{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10723, 5245) (10723, 3000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import data_format as df\n",
    "from IPython.display import clear_output\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 128\n",
    "noise_dim = 3000\n",
    "data=np.load(\"origin_data.npy\")\n",
    "try:\n",
    "    noises = np.load('noise_3000.npy')\n",
    "except:\n",
    "    print(\"makeing_noise\")\n",
    "    noises=tf.random.normal([10723, 3000])\n",
    "    np.save('noise_3000.npy', noises)\n",
    "print(data.shape , noises.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator_1():\n",
    "    inp = tf.keras.Input((noise_dim,))\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer11\", bias_regularizer=tf.keras.regularizers.l2(0.01))(inp)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer12\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer13\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn11\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/4, name=\"layer14\", bias_regularizer=tf.keras.regularizers.l2(0.01))(inp)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn12\")(x2)   \n",
    "    x = 0.5*x1 + 0.5*x2\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer21\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer22\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer23\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn21\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/4, name=\"layer24\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn22\")(x2)    \n",
    "    x = 0.5*x1 + 0.5*x2\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer31\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim, name=\"layer32\",bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer33\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn31\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/2, name=\"layer34\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn32\")(x2)   \n",
    "    x = 0.5*x1 + 0.5*x2\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer41\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim, name=\"layer42\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer43\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn41\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/2, name=\"layer44\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn42\")(x2)   \n",
    "    x = 0.5*x1 + 0.5*x2\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(data.shape[-1], name=\"layer51\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x1 = tf.keras.layers.Dense(data.shape[-1]*2, name=\"layer52\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.Dense(data.shape[-1], name=\"layer53\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1) \n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn51\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(data.shape[-1], name=\"layer54\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn52\")(x2)      \n",
    "    x = 0.5*x1 + 0.5*x2\n",
    "    \n",
    "    x = tf.keras.layers.Attention(name=\"att1\")([x, x])\n",
    "    o = x\n",
    "    \n",
    "    return tf.keras.Model(inputs=[inp], outputs=[o])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.07822514 0.0543565  0.1729703  ... 0.21795256 0.10473493 0.13076359]], shape=(1, 1311), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator_1()\n",
    "try:\n",
    "    generator.load_weights(\"gen_batch_noise_1311_1.h5\",by_name=True)\n",
    "except:\n",
    "    print(\"erro loading pre_g\")\n",
    "noise = tf.random.normal([1, 3000])\n",
    "print(generator(noise, training=False))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10722  /10723\n"
     ]
    }
   ],
   "source": [
    "out_data_1=[]\n",
    "for i in range(data.shape[0]):\n",
    "    noise = noises[i].reshape((1,noises[i].shape[0]))\n",
    "    gen = generator(noise, training=False).numpy().tolist()[0]\n",
    "    out_data_1.append(gen)\n",
    "    clear_output(wait=True)\n",
    "    print(i,\" /10723\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14057853,), (14057853,), 17.66330738488679)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_data_t = np.asarray(out_data_1).reshape((10723* 1311))\n",
    "inp_data_t = np.load(\"dense1311.npy\").reshape((10723* 1311))\n",
    "out_data_t.shape , inp_data_t.shape ,((out_data_t - inp_data_t)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator_2():\n",
    "    inp=tf.keras.Input((noise_dim,))\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer11\", bias_regularizer=tf.keras.regularizers.l2(0.01))(inp)\n",
    "    x1 = tf.nn.leaky_relu(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer12\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.nn.leaky_relu(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer13\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.nn.leaky_relu(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn11\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/4, name=\"layer14\", bias_regularizer=tf.keras.regularizers.l2(0.01))(inp)\n",
    "    x2 = tf.nn.leaky_relu(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn12\")(x2)   \n",
    "    x = 0.5*x1 + 0.5*x2\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer21\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x1 = tf.nn.leaky_relu(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer22\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.nn.leaky_relu(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer23\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.nn.leaky_relu(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn21\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/4, name=\"layer24\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x2 = tf.nn.leaky_relu(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn22\")(x2) \n",
    "    \n",
    "    x3 = tf.keras.layers.Dense(dense_dim/4, name=\"layert11\", bias_regularizer=tf.keras.regularizers.l2(0.01))(inp)\n",
    "    x3 = tf.nn.leaky_relu(x3)\n",
    "    x3 = tf.keras.layers.Dense(dense_dim/4, name=\"layert12\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x3)\n",
    "    x3 = tf.nn.leaky_relu(x3)\n",
    "    x3 = tf.keras.layers.Dense(dense_dim/4, name=\"layert13\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x3)\n",
    "    x3 = tf.nn.leaky_relu(x3)\n",
    "    \n",
    "    x_half = 0.5*x1 + 0.5*x2 + x3\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer31\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x_half)\n",
    "    x1 = tf.nn.leaky_relu(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim, name=\"layer32\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.nn.leaky_relu(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer33\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.nn.leaky_relu(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn31\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/2, name=\"layer34\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x_half)\n",
    "    x2 = tf.nn.leaky_relu(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn32\")(x2)   \n",
    "    x = 0.5*x1 + 0.5*x2\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer41\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x1 = tf.nn.leaky_relu(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim, name=\"layer42\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.nn.leaky_relu(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer43\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.nn.leaky_relu(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn41\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/2, name=\"layer44\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x2 = tf.nn.leaky_relu(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn42\")(x2)\n",
    "       \n",
    "    x3 = tf.keras.layers.Dense(dense_dim/2, name=\"layert21\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x_half)\n",
    "    x3 = tf.nn.leaky_relu(x3)\n",
    "    x3 = tf.keras.layers.Dense(dense_dim/2, name=\"layert22\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x3)\n",
    "    x3 = tf.nn.leaky_relu(x3)\n",
    "    x3 = tf.keras.layers.Dense(dense_dim/2, name=\"layert23\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x3)\n",
    "    x3 = tf.nn.leaky_relu(x3)\n",
    "    \n",
    "    x = 0.5*x1 + 0.5*x2 + x3\n",
    "    \n",
    "    x = tf.keras.layers.Attention()([x, x])\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(data.shape[-1], name=\"layer51\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x1 = tf.nn.leaky_relu(x1)\n",
    "    x1 = tf.keras.layers.Dense(data.shape[-1]*2, name=\"layer52\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.nn.leaky_relu(x1)\n",
    "    x1 = tf.keras.layers.Dense(data.shape[-1], name=\"layer53\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1) \n",
    "    x1 = tf.nn.leaky_relu(x1)\n",
    "    x2 = tf.keras.layers.Dense(data.shape[-1], name=\"layer54\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x2 = tf.nn.leaky_relu(x2)\n",
    "    o = x1 + x2\n",
    "    \n",
    "    return tf.keras.Model(inputs=[inp], outputs=[o])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.6560415   0.28336352 -9.827019   ...  0.93698055  1.3135743\n",
      "   0.32954976]], shape=(1, 2622), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator_2()\n",
    "try:\n",
    "    generator.load_weights(\"gen_batch_1311_2622.h5\", by_name=True)\n",
    "except:\n",
    "    print(\"erro loading pre_g\")\n",
    "noise = tf.random.normal([1, 1311])\n",
    "print(generator(noise, training=False))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10722  /10723\n"
     ]
    }
   ],
   "source": [
    "del inp_data_t\n",
    "del out_data_t\n",
    "out_data_2 = []\n",
    "for i in range(data.shape[0]):\n",
    "    noise= np.asarray(out_data_1[i]).reshape((1, 1311))\n",
    "    gen=generator(noise, training=False).numpy().tolist()[0]\n",
    "    out_data_2.append(gen)\n",
    "    clear_output(wait=True)\n",
    "    print(i, \" /10723\")\n",
    "del out_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28115706,), (28115706,), 145.6749346279692)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_data_t = np.asarray(out_data_2).reshape((10723* 2622))\n",
    "inp_data_t = np.load(\"dense2622.npy\").reshape((10723* 2622))\n",
    "out_data_t.shape, inp_data_t.shape, ((out_data_t - inp_data_t)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator_3():\n",
    "    inp = tf.keras.Input((noise_dim,))\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer11\", bias_regularizer=tf.keras.regularizers.l2(0.01))(inp)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer12\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer13\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn11\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/4, name=\"layer14\", bias_regularizer=tf.keras.regularizers.l2(0.01))(inp)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn12\")(x2)   \n",
    "    x = 0.5*x1 + 0.5*x2\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer21\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer22\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer23\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn21\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/4, name=\"layer24\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn22\")(x2)    \n",
    "    x = 0.5*x1 + 0.5*x2\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer31\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim, name=\"layer32\",bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer33\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn31\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/2, name=\"layer34\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn32\")(x2)   \n",
    "    x = 0.5*x1 + 0.5*x2\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer41\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim, name=\"layer42\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer43\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn41\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/2, name=\"layer44\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn42\")(x2)   \n",
    "    x = 0.5*x1 + 0.5*x2\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(data.shape[-1], name=\"layer51\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x1 = tf.keras.layers.Dense(data.shape[-1]*2, name=\"layer52\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1)\n",
    "    x1 = tf.keras.layers.Dense(data.shape[-1], name=\"layer53\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x1) \n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn51\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(data.shape[-1], name=\"layer54\", bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn52\")(x2)      \n",
    "    x = 0.5*x1 + 0.5*x2\n",
    "    \n",
    "    x = tf.keras.layers.Attention(name=\"att1\")([x, x])\n",
    "    o = x\n",
    "    \n",
    "    return tf.keras.Model(inputs=[inp], outputs=[o]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.6111403  0.18039604 0.21466637 ... 0.1621449  0.19138445 0.16518927]], shape=(1, 5245), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator_3()\n",
    "try:\n",
    "    generator.load_weights(\"gen_batch_2622_full.h5\",by_name=True)\n",
    "except:\n",
    "    print(\"erro loading pre_g\")\n",
    "noise = tf.random.normal([1, 2622])\n",
    "print(generator(noise, training=False))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10722  /10723\n"
     ]
    }
   ],
   "source": [
    "del inp_data_t\n",
    "del out_data_t\n",
    "out_data_3 = []\n",
    "for i in range(data.shape[0]):\n",
    "    noise = np.asarray(out_data_2[i]).reshape((1,2622))\n",
    "    gen = generator(noise, training=False).numpy().tolist()[0]\n",
    "    out_data_3.append(gen)\n",
    "    clear_output(wait=True)\n",
    "    print(i, \" /10723\")\n",
    "del out_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56242135,), (56242135,), 0.0967634538553412)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_data_t = np.asarray(out_data_3).reshape((10723* 5245))\n",
    "inp_data_t = np.load(\"out_1.npy\").reshape((10723* 5245))\n",
    "out_data_t.shape, inp_data_t.shape, ((out_data_t - inp_data_t)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(out_data,data,useavg=True,avgbase=5,limit=1,bigest_num=10,cut=100,n=2):\n",
    "    #資料處理\n",
    "    print(\"aprioriing data\")\n",
    "    out_file_name = \"out_dnum.txt\"\n",
    "    inp_file_name = \"input_dnum.txt\"\n",
    "    out_apriorifile_name = \"o_apriori.txt\"\n",
    "    inp_apriorifile_name = \"i_apriori.txt\"\n",
    "    inpdata=df.format_inpdata(data)\n",
    "    outdata=df.format_outdata(out_data, use_avg=useavg, avgbase=avgbase, limit=limit, bigest_num=bigest_num)\n",
    "    df.writedatafile(inpdata, outdata, inp_file_name, out_file_name)\n",
    "    df.apriori(cut, out_file_name, out_apriorifile_name)\n",
    "    df.apriori(cut, inp_file_name, inp_apriorifile_name)\n",
    "    #顯示結果\n",
    "    print(\"showing data\")\n",
    "    print(\"n=1\")\n",
    "    inp_seq_y, inp_seq_x = df.read_n_seq(inp_apriorifile_name, 1)\n",
    "    out_seq_y, out_seq_x = df.read_n_seq(out_apriorifile_name, 1)\n",
    "    df.plt_format(inp_seq_x, inp_seq_y, out_seq_x, out_seq_y)\n",
    "    print(\"n=\",n)\n",
    "    inp_seq_y, inp_seq_x = df.read_n_seq(inp_apriorifile_name, n)\n",
    "    out_seq_y, out_seq_x = df.read_n_seq(out_apriorifile_name, n)\n",
    "    df.plt_format(inp_seq_x, inp_seq_y, out_seq_x, out_seq_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aprioriing data\n",
      "total_data_long: 107230\n",
      "time: 0.32s\n",
      "time: 4.86s\n",
      "showing data\n",
      "n=1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse= 32785.28575443563\n",
      "cos 0.7370380372913496\n",
      "pccs (0.19217760282900823, 0.0011349562757190942)\n",
      "n= 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse= 71952.30593942074\n",
      "cos 0.9400179896889052\n",
      "pccs (-0.13766529607884892, 1.041378783105899e-06)\n"
     ]
    }
   ],
   "source": [
    "show_result(out_data_3, data, avgbase=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#偏移量\n",
    "#model 1 -> model 2\n",
    "#1.5406178593411157 = 184.73132150360726/72.71117961499158-1\n",
    "\n",
    "#model 2 -> model 3 \n",
    "#5.906206255587159 = 0.2504970636264649/0.03627129777999483-1\n",
    "\n",
    "#前模組對後模組的影響率 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
