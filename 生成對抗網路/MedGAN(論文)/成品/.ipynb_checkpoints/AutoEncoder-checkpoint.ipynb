{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10723, 5245), (10723, 2622))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "data=np.load('origin_data.npy')\n",
    "noise_dim=data.shape[-1]\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 512\n",
    "noises=np.random.normal(0,1,size=([data.shape[0], int(data.shape[-1]/2)]))\n",
    "data.shape ,noises.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class relu_constraint(tf.keras.constraints.Constraint):\n",
    "    def __call__(self, w):\n",
    "        return tf.nn.relu(w)\n",
    "\n",
    "    def get_config(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.5110252  0.49242178 0.49941906 ... 0.48797417 0.5126568  0.51690376]], shape=(1, 5245), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dense_dim = data.shape[-1]\n",
    "def b_VAE():\n",
    "    inp = tf.keras.Input((data.shape[-1],))\n",
    "    noise_inp = tf.keras.Input((int(data.shape[-1]/2),))\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim, name=\"layer11\", trainable=False)(inp)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim, name=\"layer12\", trainable=False)(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim, name=\"layer13\", trainable=False)(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim, name=\"layerh1\", trainable=False)(inp)\n",
    "    x = x1 + x2\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim, name=\"layer21\", trainable=False)(x)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim, name=\"layer22\", trainable=False)(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer23\", trainable=False)(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/2, name=\"layerh2\", trainable=False)(x)\n",
    "    x = x1 + x2\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    \n",
    "    xdot = tf.keras.layers.Dense(dense_dim, name=\"layerd11\", trainable=False)(inp)\n",
    "    xdot = tf.keras.layers.Dense(dense_dim, name=\"layerd12\", trainable=False)(xdot)\n",
    "    xdot = tf.keras.layers.Dense(dense_dim/2, name=\"layerd13\", trainable=False)(xdot)\n",
    "    xdot = tf.keras.layers.Dense(dense_dim/2, name=\"layerd14\", trainable=False)(xdot)\n",
    "    xhdot = tf.keras.layers.Dense(dense_dim/2, name=\"layerd15\", trainable=False)(inp)\n",
    "    xdot = xdot + xhdot\n",
    "    \n",
    "    x = xdot*noise_inp + x\n",
    "    xo = tf.nn.tanh(x)\n",
    "\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim*4, kernel_regularizer=tf.keras.regularizers.l1(0.), name=\"layert11\", trainable=False)(xo)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim, name=\"layert12\", trainable=False)(x1)\n",
    "    x = tf.keras.layers.Dense(dense_dim, name=\"layert13\", trainable=False)(x1)\n",
    "    x = tf.keras.layers.LayerNormalization(name=\"lnt1\")(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim*4, kernel_regularizer=tf.keras.regularizers.l1(0.), name=\"layert21\", trainable=False)(x)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim, name=\"layert22\", trainable=False)(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim, name=\"layert23\", trainable=False)(x1)\n",
    "    xt = x1\n",
    "    xb = tf.nn.sigmoid(xt)\n",
    "    \n",
    "        \n",
    "    x1 = tf.keras.layers.Dense(dense_dim*2, name=\"layert31\", kernel_regularizer=tf.keras.regularizers.l1(0.))(xb)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim, name=\"layert32\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim*2, name=\"layert33\", kernel_regularizer=tf.keras.regularizers.l1(0.))(xb)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim, name=\"layert34\")(x2)\n",
    "    x3 = tf.keras.layers.Dense(dense_dim*2, name=\"layert35\", kernel_regularizer=tf.keras.regularizers.l1(0.))(xb)\n",
    "    x3 = tf.keras.layers.Dense(dense_dim, name=\"layert36\")(x2)\n",
    "\n",
    "    xv = tf.concat([x1, x2, x3, xb], 1)\n",
    "    xv = tf.keras.layers.Dense(dense_dim/2, name=\"layert37\")(xv)\n",
    "    xv = tf.keras.layers.Dense(noise_dim/4, name=\"layert38\")(xv)\n",
    "    xv = tf.keras.layers.Dense(noise_dim/8, name=\"layert39\")(xv)\n",
    "    xv1 = tf.keras.layers.Dense(1, activation='sigmoid', name=\"layertv1\")(xv)\n",
    "    xv2 = tf.keras.layers.Dense(1, activation='sigmoid', name=\"layertv2\")(xv)\n",
    "    xv3 = tf.keras.layers.Dense(1, activation='sigmoid', name=\"layertv3\")(xv)\n",
    "    x = 0.33*x1*xv1 + 0.33*x2*xv2 + 0.33*x3*xv3\n",
    "    \n",
    "    x = 0.05*xt + 0.8*x\n",
    "    x = tf.nn.sigmoid(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=[inp, noise_inp], outputs=x)\n",
    "VAE=b_VAE()\n",
    "data_test = tf.random.normal([1, data.shape[-1]])\n",
    "noise = tf.random.normal([1, int(data.shape[-1]/2)])\n",
    "print(VAE([data_test, noise], training=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 9s 293ms/step - loss: 46.9154\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 9s 293ms/step - loss: 46.2759\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 9s 293ms/step - loss: 46.1365\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 9s 294ms/step - loss: 46.0861\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 9s 294ms/step - loss: 46.0633\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 9s 294ms/step - loss: 46.0518\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 9s 295ms/step - loss: 45.9981\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 9s 294ms/step - loss: 46.0250\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 9s 295ms/step - loss: 45.9681\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 9s 295ms/step - loss: 46.0046\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 9s 294ms/step - loss: 46.0161\n",
      "Epoch 12/20\n",
      " 3/32 [=>............................] - ETA: 5s - loss: 47.2643"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-59e438eb9965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  loss=tf.keras.losses.CategoricalCrossentropy())\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoises\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 1e-1\n",
    "VAE.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=lr),\\\n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy())\n",
    "for _ in range(5000):\n",
    "    VAE.fit(x=[data,noises], y=data, batch_size=int(data.shape[0]/32)+1, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未還原平均率: 8.25661718279747 %\n",
      "錯誤平均比例: 0.043639879602721206 %\n",
      "錯誤平均個數: 2.2889116851627276 個\n"
     ]
    }
   ],
   "source": [
    "noises=np.random.normal(0,1,size=([data.shape[0], int(data.shape[-1]/2)]))\n",
    "avg = 0.5\n",
    "erro = 0\n",
    "no_c = 0\n",
    "for i in range(len(data)):\n",
    "    tmp  = VAE([data[i].reshape((1,data[i].shape[-1])),\\\n",
    "               noises[i].reshape((1,noises[i].shape[-1]))],training = False)\n",
    "    tmp = tmp.numpy()[0].tolist()\n",
    "    out = []\n",
    "    for element in tmp:\n",
    "        if(element<avg):\n",
    "            out.append(0)\n",
    "        else:\n",
    "            out.append(1)\n",
    "    c=0\n",
    "    for n in (data[i] - out):\n",
    "        if(n==1):\n",
    "            c+=1\n",
    "    if(sum(data[i]) == 0):\n",
    "        tmp_c = 0\n",
    "    else:\n",
    "        tmp_c = c/sum(data[i])*100\n",
    "    no_c += tmp_c\n",
    "    clear_output(wait=True)\n",
    "    print(i,\"/10723\")\n",
    "    print(\"原資料未還原率:\", int(tmp_c),\"%\")\n",
    "    print(\"資料前10筆比對:\")\n",
    "    print(out[:10])\n",
    "    print(data[i][:10])\n",
    "    print(\"錯誤個數:\", sum(abs(out - data[i])))\n",
    "    print(\"錯誤比例:\", sum(abs(out - data[i]))/data.shape[-1])\n",
    "    erro+=sum(abs(out - data[i])) / data.shape[-1]\n",
    "    #time.sleep(0.1)\n",
    "clear_output(wait=True)\n",
    "print(\"未還原平均率:\", no_c/len(data), \"%\")\n",
    "print(\"錯誤平均比例:\", erro/len(data)*100, \"%\")\n",
    "print(\"錯誤平均個數:\", erro/len(data)*data.shape[-1], \"個\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE.save_weights(\"VAE_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE_data = np.zeros((10723,5245))\n",
    "noises=np.random.normal(0,1,size=([data.shape[0], int(data.shape[-1]/2)]))\n",
    "for i in range(len(data)):\n",
    "    tmp  = VAE([data[i].reshape((1,data[i].shape[-1])),\\\n",
    "               noises[i].reshape((1,noises[i].shape[-1]))],training = False)\n",
    "    VAE_data[i] = tmp.numpy()[0]\n",
    "    \n",
    "np.save('VAE_data.npy',data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
