{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10723, 5245)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import data_format as df\n",
    "import numpy as np\n",
    "import time\n",
    "data=np.load('origin_data.npy')\n",
    "data_tmp = np.load(\"VAE_data.npy\")\n",
    "noise_dim=1000\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 128\n",
    "pre_train=False\n",
    "gen_savemodel = \"gen_model.h5\"\n",
    "disc_savemodel = \"disc_model.h5\"\n",
    "tmp_model = \"tmp_model_new.h5\"\n",
    "noises = tf.random.normal([data.shape[0], noise_dim])\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, data_tmp, noises)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_dim=data.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.77811867 0.40687513 0.84855235 ... 0.70048165 0.9058117  0.7617537 ]], shape=(1, 5245), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def b_g():\n",
    "    inp = tf.keras.Input((noise_dim,))\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer11\")(inp)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/8, name=\"layer12\")(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer13\")(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn11\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/4, name=\"layer14\")(inp)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn12\")(x2)   \n",
    "    x = 0.75*x1 + 0.25*x2\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer21\")(x)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/8, name=\"layer22\")(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer23\")(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn21\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/4, name=\"layer24\")(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn22\")(x2)    \n",
    "    x = 0.75*x1 + 0.25*x2\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer31\")(x)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/4, name=\"layer32\")(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer33\")(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn31\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim/2, name=\"layer34\")(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn32\")(x2)   \n",
    "    x = 0.75*x1 + 0.25*x2\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(dense_dim*2, name=\"layer41\")(x)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim/2, name=\"layer42\")(x1)\n",
    "    x1 = tf.keras.layers.Dense(dense_dim,name=\"layer43\")(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn41\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(dense_dim, name=\"layer44\")(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn42\")(x2)   \n",
    "    xq = 0.75*x1 + 0.25*x2\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(data.shape[-1]*2, name=\"layer51\")(x)\n",
    "    x1 = tf.keras.layers.Dense(data.shape[-1]/2, name=\"layer52\")(x1)\n",
    "    x1 = tf.keras.layers.Dense(data.shape[-1], name=\"layer53\")(x1) \n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn51\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(data.shape[-1], name=\"layer54\")(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn52\")(x2)      \n",
    "    xv = 0.75*x1 + 0.25*x2\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(data.shape[-1]*2, name=\"layer61\")(x)\n",
    "    x1 = tf.keras.layers.Dense(data.shape[-1]/2, name=\"layer62\")(x1)\n",
    "    x1 = tf.keras.layers.Dense(data.shape[-1], name=\"layer63\")(x1) \n",
    "    x1 = tf.keras.layers.BatchNormalization(name=\"bn61\")(x1)\n",
    "    x2 = tf.keras.layers.Dense(data.shape[-1], name=\"layer64\")(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization(name=\"bn62\")(x2)      \n",
    "    xk = 0.75*x1 + 0.25*x2\n",
    "    \n",
    "    x = tf.keras.layers.Attention(name=\"att1\")([xq, xv, xk])\n",
    "    x = x + xv\n",
    "    o = tf.nn.sigmoid(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp],outputs=[o])\n",
    "generator=b_g()\n",
    "try:\n",
    "    generator.load_weights(gen_savemodel, by_name=True)\n",
    "except:\n",
    "    print(\"erro loading g\")\n",
    "noise = tf.random.normal([1, noise_dim])\n",
    "print(generator(noise, training=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.81750244]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def b_d():\n",
    "    inpout = tf.keras.Input(shape=(data.shape[-1],))\n",
    "    xq = tf.keras.layers.Dense(dense_dim*2, name=\"layera11\")(inpout)\n",
    "    xq = tf.keras.layers.Dense(dense_dim/2, name=\"layera14\")(xq)\n",
    "    xq = tf.keras.layers.Dense(dense_dim/4, name=\"layera12\")(xq)\n",
    "    xq = tf.keras.layers.Dense(dense_dim/8, name=\"layera13\")(xq)\n",
    "    \n",
    "    xv = tf.keras.layers.Dense(dense_dim*2, name=\"layera21\")(inpout)  \n",
    "    xv = tf.keras.layers.Dense(dense_dim/2, name=\"layera24\")(xv)  \n",
    "    xv = tf.keras.layers.Dense(dense_dim/4, name=\"layera22\")(xv)   \n",
    "    xv = tf.keras.layers.Dense(dense_dim/8, name=\"layera23\")(xv)\n",
    "    \n",
    "    x = tf.keras.layers.Attention(name=\"att\")([xq,xv])\n",
    "    x = x + xv\n",
    "    x = tf.keras.layers.LayerNormalization(name=\"ln1\")(x)\n",
    "    \n",
    "    o = tf.keras.layers.Dense(1, name=\"layero\")(x)\n",
    "    return tf.keras.Model(inputs=inpout, outputs=[o])\n",
    "    \n",
    "discriminator = b_d()\n",
    "try:\n",
    "    discriminator.load_weights(disc_savemodel)\n",
    "except:\n",
    "    print(\"erro loading d\")\n",
    "print(discriminator(generator(noise, training=False),training=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = tf.reduce_mean(tf.nn.relu(1.0 - real_output))\n",
    "    fake_loss = tf.reduce_mean(tf.nn.relu(1.0 + fake_output))\n",
    "    loss = real_loss + fake_loss\n",
    "    total_loss = real_loss + fake_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return -tf.reduce_mean(fake_output)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-6)\n",
    "\n",
    "discriminator_optimizer_low = tf.keras.optimizers.Adam(1e-8)\n",
    "discriminator_optimizer_high = tf.keras.optimizers.SGD(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_g(images,noise):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_all(images,images_tmp,noise):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images, gen_tmp = generator(noise, training=True)\n",
    "        real_tmp_output = discriminator_tmp(images_tmp, training=True)\n",
    "        fake_tmp_output = discriminator_tmp(gen_tmp, training=True)\n",
    "        \n",
    "        gen_loss_tmp = generator_loss(fake_tmp_output)\n",
    "        disc_loss_tmp = discriminator_loss(real_tmp_output, fake_tmp_output)\n",
    "        \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss_tmp, generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "        \n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss_tmp, discriminator_tmp.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator_tmp.trainable_variables))\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images,gen_tmp = generator(noise, training=True)\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    \n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss , disc_loss\n",
    "def train(dataset, epochs):\n",
    "    best_model_loss = []\n",
    "    loss_history = []\n",
    "    best_s = 0\n",
    "    for epoch in range(epochs):\n",
    "        st = time.time()\n",
    "        for i, tmp, noise in dataset:\n",
    "            _ = train_step_g(noise)\n",
    "            gen_loss, disc_loss = train_step_all(i, tmp, noise)\n",
    "        disc_loss_ = float(disc_loss) + 1e-24\n",
    "        gen_loss_  = float(gen_loss) + 1e-24\n",
    "        if(best_model_loss == [] or abs(best_model_loss[0]/best_model_loss[1]*disc_loss_) >= abs(gen_loss_)):\n",
    "            best_model_loss = [gen_loss_, disc_loss_]\n",
    "            generator.save_weights(gen_savemodel)\n",
    "            discriminator.save_weights(disc_savemodel)\n",
    "            print(\"epoch \", epoch, \" time:\", time.time() - st, \"                           best_score\")\n",
    "        else:\n",
    "            print(\"epoch \", epoch, \" time:\", time.time() - st)\n",
    "        print(\"gen_loss:\", float(gen_loss), \" disc_loss:\", float(disc_loss))\n",
    "        if((disc_loss_-abs(gen_loss_)) >= best_s and disc_loss_ < 3):\n",
    "            best_s = disc_loss_-abs(gen_loss_)\n",
    "            with open(\"log_train.txt\", \"a\") as w:\n",
    "                w.write(\"tmp_saving:\" + str(best_s) + \"\\n\")\n",
    "            print(\"tmp_saving:\", best_s)\n",
    "            generator.save_weights(tmp_model)\n",
    "        if(abs(gen_loss_) > disc_loss_):\n",
    "            best_s = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  time: 40.95504021644592                            best_score\n",
      "gen_loss: -7.289137840270996  disc_loss: 10.101583480834961\n",
      "epoch  1  time: 27.642393827438354\n",
      "gen_loss: -14.510453224182129  disc_loss: 17.294841766357422\n",
      "epoch  2  time: 27.624217987060547\n",
      "gen_loss: -20.62030792236328  disc_loss: 23.754907608032227\n",
      "epoch  3  time: 27.597025871276855\n",
      "gen_loss: -24.292348861694336  disc_loss: 26.46209144592285\n",
      "epoch  4  time: 27.63445019721985\n",
      "gen_loss: -27.3171443939209  disc_loss: 29.55553436279297\n",
      "epoch  5  time: 27.6438250541687\n",
      "gen_loss: -28.640743255615234  disc_loss: 30.502363204956055\n",
      "epoch  6  time: 27.609620571136475\n",
      "gen_loss: -31.941598892211914  disc_loss: 33.78144454956055\n",
      "epoch  7  time: 27.589239358901978\n",
      "gen_loss: -32.6096076965332  disc_loss: 34.541351318359375\n",
      "epoch  8  time: 27.62264657020569\n",
      "gen_loss: -30.54063606262207  disc_loss: 32.759056091308594\n",
      "epoch  9  time: 27.64548921585083\n",
      "gen_loss: -32.81209182739258  disc_loss: 34.408958435058594\n",
      "epoch  10  time: 27.667259454727173\n",
      "gen_loss: -32.98843002319336  disc_loss: 34.53736877441406\n",
      "epoch  11  time: 27.650765657424927\n",
      "gen_loss: -30.34514045715332  disc_loss: 31.91389274597168\n",
      "epoch  12  time: 27.655895948410034\n",
      "gen_loss: -30.157127380371094  disc_loss: 31.61298179626465\n",
      "epoch  13  time: 27.675439834594727\n",
      "gen_loss: -33.58993148803711  disc_loss: 35.08186340332031\n",
      "epoch  14  time: 27.622443675994873\n",
      "gen_loss: -34.867984771728516  disc_loss: 36.142181396484375\n",
      "epoch  15  time: 27.660106897354126\n",
      "gen_loss: -34.77413558959961  disc_loss: 36.00201416015625\n",
      "epoch  16  time: 27.653889179229736\n",
      "gen_loss: -34.96329879760742  disc_loss: 36.24341583251953\n",
      "epoch  17  time: 27.64819073677063\n",
      "gen_loss: -34.830745697021484  disc_loss: 35.94221115112305\n",
      "epoch  18  time: 27.65762710571289\n",
      "gen_loss: -34.91265106201172  disc_loss: 36.190093994140625\n",
      "epoch  19  time: 27.667333364486694\n",
      "gen_loss: -33.658843994140625  disc_loss: 34.856143951416016\n",
      "epoch  20  time: 27.6627414226532\n",
      "gen_loss: -33.252445220947266  disc_loss: 34.328495025634766\n",
      "epoch  21  time: 27.669256687164307\n",
      "gen_loss: -34.65022659301758  disc_loss: 35.7418327331543\n",
      "epoch  22  time: 27.674522876739502\n",
      "gen_loss: -31.948198318481445  disc_loss: 33.153587341308594\n",
      "epoch  23  time: 27.664151430130005\n",
      "gen_loss: -34.991729736328125  disc_loss: 36.12226104736328\n",
      "epoch  24  time: 27.673912525177002\n",
      "gen_loss: -34.08373260498047  disc_loss: 35.33892822265625\n",
      "epoch  25  time: 27.642902851104736\n",
      "gen_loss: -31.466976165771484  disc_loss: 32.618202209472656\n",
      "epoch  26  time: 27.6590518951416\n",
      "gen_loss: -35.051544189453125  disc_loss: 36.156517028808594\n",
      "epoch  27  time: 27.662646532058716\n",
      "gen_loss: -34.90469741821289  disc_loss: 35.99897766113281\n",
      "epoch  28  time: 27.672778367996216\n",
      "gen_loss: -34.45638656616211  disc_loss: 35.59142303466797\n",
      "epoch  29  time: 27.65385103225708\n",
      "gen_loss: -35.002227783203125  disc_loss: 36.13008499145508\n",
      "epoch  30  time: 27.6195707321167\n",
      "gen_loss: -34.64451217651367  disc_loss: 35.68647384643555\n",
      "epoch  31  time: 27.64253878593445\n",
      "gen_loss: -30.15371322631836  disc_loss: 31.25862693786621\n",
      "epoch  32  time: 27.653218746185303\n",
      "gen_loss: -34.738685607910156  disc_loss: 35.85921859741211\n",
      "epoch  33  time: 27.635270833969116\n",
      "gen_loss: -32.77090072631836  disc_loss: 33.83059310913086\n",
      "epoch  34  time: 27.653566598892212\n",
      "gen_loss: -33.81093215942383  disc_loss: 34.87727737426758\n",
      "epoch  35  time: 27.63385534286499\n",
      "gen_loss: -27.039600372314453  disc_loss: 28.08205223083496\n",
      "epoch  36  time: 27.644365310668945\n",
      "gen_loss: -33.537410736083984  disc_loss: 34.585914611816406\n",
      "epoch  37  time: 27.65442180633545\n",
      "gen_loss: -34.158416748046875  disc_loss: 35.26152801513672\n",
      "epoch  38  time: 27.65574288368225\n",
      "gen_loss: -33.322994232177734  disc_loss: 34.395748138427734\n",
      "epoch  39  time: 27.638282537460327\n",
      "gen_loss: -33.46622085571289  disc_loss: 34.52690124511719\n",
      "epoch  40  time: 27.632144689559937\n",
      "gen_loss: -33.22382736206055  disc_loss: 34.3017692565918\n",
      "epoch  41  time: 27.653916120529175\n",
      "gen_loss: -32.6986198425293  disc_loss: 33.73258590698242\n",
      "epoch  42  time: 27.637598276138306\n",
      "gen_loss: -33.6606559753418  disc_loss: 34.746524810791016\n",
      "epoch  43  time: 27.666171312332153\n",
      "gen_loss: -27.906387329101562  disc_loss: 29.03339195251465\n",
      "epoch  44  time: 27.629220247268677\n",
      "gen_loss: -33.040870666503906  disc_loss: 34.064666748046875\n",
      "epoch  45  time: 27.65600895881653\n",
      "gen_loss: -31.4118595123291  disc_loss: 32.46514892578125\n",
      "epoch  46  time: 27.659770727157593\n",
      "gen_loss: -31.96578025817871  disc_loss: 32.998565673828125\n",
      "epoch  47  time: 27.63110613822937\n",
      "gen_loss: -29.418718338012695  disc_loss: 30.44245719909668\n",
      "epoch  48  time: 27.651228427886963\n",
      "gen_loss: -29.064640045166016  disc_loss: 30.081819534301758\n",
      "epoch  49  time: 27.63744568824768\n",
      "gen_loss: -20.89706802368164  disc_loss: 22.014331817626953\n",
      "epoch  50  time: 27.628265380859375\n",
      "gen_loss: -22.341806411743164  disc_loss: 23.414905548095703\n",
      "epoch  51  time: 27.614811420440674\n",
      "gen_loss: -30.56586456298828  disc_loss: 31.648365020751953\n",
      "epoch  52  time: 27.655186414718628\n",
      "gen_loss: -29.664945602416992  disc_loss: 30.69923210144043\n",
      "epoch  53  time: 27.654371976852417\n",
      "gen_loss: -24.422988891601562  disc_loss: 25.51234245300293\n",
      "epoch  54  time: 27.661022186279297\n",
      "gen_loss: -15.485053062438965  disc_loss: 16.609798431396484\n",
      "epoch  55  time: 27.655146598815918\n",
      "gen_loss: -30.316770553588867  disc_loss: 31.369253158569336\n",
      "epoch  56  time: 27.645347118377686\n",
      "gen_loss: -30.667110443115234  disc_loss: 31.73342514038086\n",
      "epoch  57  time: 27.651188850402832\n",
      "gen_loss: -22.486894607543945  disc_loss: 23.524518966674805\n",
      "epoch  58  time: 27.620839834213257\n",
      "gen_loss: -14.769354820251465  disc_loss: 15.832561492919922\n",
      "epoch  59  time: 27.660285711288452\n",
      "gen_loss: -26.898723602294922  disc_loss: 27.93819236755371\n",
      "epoch  60  time: 27.647521018981934\n",
      "gen_loss: -19.501745223999023  disc_loss: 20.559125900268555\n",
      "epoch  61  time: 27.646968364715576\n",
      "gen_loss: -16.4014835357666  disc_loss: 17.922391891479492\n",
      "epoch  62  time: 27.617425203323364\n",
      "gen_loss: -22.353429794311523  disc_loss: 23.49732208251953\n",
      "epoch  63  time: 27.645621061325073\n",
      "gen_loss: -25.889219284057617  disc_loss: 26.936307907104492\n",
      "epoch  64  time: 27.640395641326904\n",
      "gen_loss: -23.867321014404297  disc_loss: 24.915863037109375\n",
      "epoch  65  time: 27.65697956085205\n",
      "gen_loss: -9.114526748657227  disc_loss: 10.381427764892578\n",
      "epoch  66  time: 27.65412139892578\n",
      "gen_loss: -15.920889854431152  disc_loss: 17.017311096191406\n",
      "epoch  67  time: 27.651695013046265\n",
      "gen_loss: -23.41364288330078  disc_loss: 24.481590270996094\n",
      "epoch  68  time: 27.615103483200073\n",
      "gen_loss: -16.08300018310547  disc_loss: 17.1473445892334\n",
      "epoch  69  time: 27.63982129096985\n",
      "gen_loss: -23.511266708374023  disc_loss: 24.5207462310791\n",
      "epoch  70  time: 27.65228295326233\n",
      "gen_loss: -17.055763244628906  disc_loss: 18.12551498413086\n",
      "epoch  71  time: 27.639628887176514\n",
      "gen_loss: -23.54921531677246  disc_loss: 24.638944625854492\n",
      "epoch  72  time: 27.643784999847412\n",
      "gen_loss: -18.98386001586914  disc_loss: 20.081893920898438\n",
      "epoch  73  time: 27.633790731430054\n",
      "gen_loss: -11.970386505126953  disc_loss: 13.037262916564941\n",
      "epoch  74  time: 27.638155698776245\n",
      "gen_loss: -21.42122459411621  disc_loss: 22.491329193115234\n",
      "epoch  75  time: 27.656962871551514\n",
      "gen_loss: -21.1459903717041  disc_loss: 22.353862762451172\n",
      "epoch  76  time: 27.66074013710022\n",
      "gen_loss: -20.123687744140625  disc_loss: 21.200796127319336\n",
      "epoch  77  time: 27.65522289276123\n",
      "gen_loss: -18.922208786010742  disc_loss: 19.987272262573242\n",
      "epoch  78  time: 27.6312735080719\n",
      "gen_loss: -16.856229782104492  disc_loss: 17.953914642333984\n",
      "epoch  79  time: 27.657750844955444\n",
      "gen_loss: -12.76977252960205  disc_loss: 13.789711952209473\n",
      "epoch  80  time: 27.64602756500244\n",
      "gen_loss: -5.564763069152832  disc_loss: 6.784048557281494\n",
      "epoch  81  time: 27.66200590133667\n",
      "gen_loss: -17.403148651123047  disc_loss: 18.4967041015625\n",
      "epoch  82  time: 27.649465560913086\n",
      "gen_loss: -16.986248016357422  disc_loss: 18.114578247070312\n",
      "epoch  83  time: 27.62670087814331\n",
      "gen_loss: -16.40812873840332  disc_loss: 17.49622344970703\n",
      "epoch  84  time: 27.63137149810791\n",
      "gen_loss: -13.252163887023926  disc_loss: 14.319231986999512\n",
      "epoch  85  time: 27.663350343704224\n",
      "gen_loss: -15.06476879119873  disc_loss: 16.107685089111328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  86  time: 27.65148901939392\n",
      "gen_loss: -8.16343879699707  disc_loss: 9.225481033325195\n",
      "epoch  87  time: 27.651328086853027\n",
      "gen_loss: -10.392850875854492  disc_loss: 11.507386207580566\n",
      "epoch  88  time: 27.65036129951477\n",
      "gen_loss: -7.373831748962402  disc_loss: 8.506096839904785\n",
      "epoch  89  time: 27.66358470916748\n",
      "gen_loss: -8.582086563110352  disc_loss: 9.716947555541992\n",
      "epoch  90  time: 27.65670394897461\n",
      "gen_loss: -6.008330821990967  disc_loss: 7.681589126586914\n",
      "epoch  91  time: 27.65074872970581\n",
      "gen_loss: -11.987948417663574  disc_loss: 13.060101509094238\n",
      "epoch  92  time: 27.64322781562805\n",
      "gen_loss: -13.0806245803833  disc_loss: 14.18036937713623\n",
      "epoch  93  time: 27.65746831893921\n",
      "gen_loss: -13.062755584716797  disc_loss: 14.151504516601562\n",
      "epoch  94  time: 34.25200080871582                            best_score\n",
      "gen_loss: -2.1624534130096436  disc_loss: 4.382406711578369\n",
      "epoch  95  time: 27.692503452301025\n",
      "gen_loss: -7.155481815338135  disc_loss: 8.207769393920898\n",
      "epoch  96  time: 27.645832538604736\n",
      "gen_loss: -3.443955898284912  disc_loss: 4.931582927703857\n",
      "epoch  97  time: 27.646997690200806\n",
      "gen_loss: -4.395957946777344  disc_loss: 5.533815860748291\n",
      "epoch  98  time: 27.666763067245483\n",
      "gen_loss: 4.155681133270264  disc_loss: 0.31900957226753235\n",
      "epoch  99  time: 27.640987157821655\n",
      "gen_loss: -11.078752517700195  disc_loss: 12.300189971923828\n",
      "epoch  100  time: 34.167314291000366                            best_score\n",
      "gen_loss: -2.487211227416992  disc_loss: 5.1426825523376465\n",
      "epoch  101  time: 27.672581672668457\n",
      "gen_loss: -6.797129154205322  disc_loss: 7.924720764160156\n",
      "epoch  102  time: 27.644286394119263\n",
      "gen_loss: -4.376033782958984  disc_loss: 6.104890823364258\n",
      "epoch  103  time: 27.65021514892578\n",
      "gen_loss: -5.793654441833496  disc_loss: 6.910443305969238\n",
      "epoch  104  time: 27.657665252685547\n",
      "gen_loss: -2.907623529434204  disc_loss: 4.090991497039795\n",
      "epoch  105  time: 27.64879059791565\n",
      "gen_loss: 10.115880012512207  disc_loss: 0.11702948063611984\n",
      "epoch  106  time: 27.655792474746704\n",
      "gen_loss: -4.162935733795166  disc_loss: 5.305241107940674\n",
      "epoch  107  time: 27.656654357910156\n",
      "gen_loss: -2.985973596572876  disc_loss: 4.061150074005127\n",
      "epoch  108  time: 27.65139079093933\n",
      "gen_loss: 7.0419416427612305  disc_loss: 0.12942641973495483\n",
      "epoch  109  time: 27.64274525642395\n",
      "gen_loss: -2.493119955062866  disc_loss: 3.586580514907837\n",
      "epoch  110  time: 27.628575801849365\n",
      "gen_loss: -3.990382432937622  disc_loss: 5.252435207366943\n",
      "epoch  111  time: 27.652748584747314\n",
      "gen_loss: -10.709181785583496  disc_loss: 11.868294715881348\n",
      "epoch  112  time: 27.64520812034607\n",
      "gen_loss: -7.994171619415283  disc_loss: 9.118162155151367\n",
      "epoch  113  time: 27.657852172851562\n",
      "gen_loss: -6.982470989227295  disc_loss: 8.07071590423584\n",
      "epoch  114  time: 27.65989112854004\n",
      "gen_loss: -10.270868301391602  disc_loss: 11.449849128723145\n",
      "epoch  115  time: 27.620222568511963\n",
      "gen_loss: 9.107414245605469  disc_loss: 0.049841929227113724\n",
      "epoch  116  time: 27.661125659942627\n",
      "gen_loss: -11.738191604614258  disc_loss: 12.838569641113281\n",
      "epoch  117  time: 27.65249466896057\n",
      "gen_loss: -8.965547561645508  disc_loss: 10.586594581604004\n",
      "epoch  118  time: 27.64155387878418\n",
      "gen_loss: -5.897493839263916  disc_loss: 7.034204959869385\n",
      "epoch  119  time: 27.65894842147827\n",
      "gen_loss: -10.300233840942383  disc_loss: 11.401453018188477\n",
      "epoch  120  time: 27.6348135471344\n",
      "gen_loss: -6.398054599761963  disc_loss: 7.508689880371094\n",
      "epoch  121  time: 27.670204639434814\n",
      "gen_loss: -14.840779304504395  disc_loss: 16.001144409179688\n",
      "epoch  122  time: 27.63948082923889\n",
      "gen_loss: -9.509016036987305  disc_loss: 10.751352310180664\n",
      "epoch  123  time: 27.616987466812134\n",
      "gen_loss: -13.57437801361084  disc_loss: 14.737871170043945\n",
      "epoch  124  time: 27.605842351913452\n",
      "gen_loss: -6.780759334564209  disc_loss: 7.954469203948975\n",
      "epoch  125  time: 27.635502576828003\n",
      "gen_loss: 5.499882221221924  disc_loss: 0.6765438318252563\n",
      "epoch  126  time: 27.62941884994507\n",
      "gen_loss: -8.02437973022461  disc_loss: 9.19221019744873\n",
      "epoch  127  time: 27.647214651107788\n",
      "gen_loss: -6.664902687072754  disc_loss: 7.836564064025879\n",
      "epoch  128  time: 27.64571213722229\n",
      "gen_loss: -10.669427871704102  disc_loss: 11.852927207946777\n",
      "epoch  129  time: 27.66002058982849\n",
      "gen_loss: -11.695780754089355  disc_loss: 12.80848503112793\n",
      "epoch  130  time: 27.662020444869995\n",
      "gen_loss: -10.344182014465332  disc_loss: 11.545141220092773\n",
      "epoch  131  time: 27.671842098236084\n",
      "gen_loss: -11.396614074707031  disc_loss: 12.575358390808105\n",
      "epoch  132  time: 27.666691780090332\n",
      "gen_loss: -6.68784761428833  disc_loss: 7.858253002166748\n",
      "epoch  133  time: 27.648813724517822\n",
      "gen_loss: 5.405538082122803  disc_loss: 2.290560722351074\n",
      "epoch  134  time: 27.646044492721558\n",
      "gen_loss: -8.945724487304688  disc_loss: 10.119543075561523\n",
      "epoch  135  time: 27.642627954483032\n",
      "gen_loss: -4.152371406555176  disc_loss: 5.383626937866211\n",
      "epoch  136  time: 27.641584634780884\n",
      "gen_loss: -12.040678977966309  disc_loss: 13.278739929199219\n",
      "epoch  137  time: 27.64983344078064\n",
      "gen_loss: 12.05850601196289  disc_loss: 0.13915441930294037\n",
      "epoch  138  time: 27.645399808883667\n",
      "gen_loss: -8.525059700012207  disc_loss: 9.648694038391113\n",
      "epoch  139  time: 27.664249181747437\n",
      "gen_loss: -7.079405307769775  disc_loss: 8.204026222229004\n",
      "epoch  140  time: 27.672475576400757\n",
      "gen_loss: -4.661917686462402  disc_loss: 6.386362552642822\n",
      "epoch  141  time: 27.6492121219635\n",
      "gen_loss: -4.1064934730529785  disc_loss: 5.420866966247559\n",
      "epoch  142  time: 27.62998628616333\n",
      "gen_loss: 7.5441670417785645  disc_loss: 0.16010837256908417\n",
      "epoch  143  time: 27.64230251312256\n",
      "gen_loss: -2.6114068031311035  disc_loss: 3.8203980922698975\n",
      "epoch  144  time: 27.65918779373169\n",
      "gen_loss: 15.23713207244873  disc_loss: 0.09790447354316711\n",
      "epoch  145  time: 27.632237195968628\n",
      "gen_loss: 6.756414413452148  disc_loss: 1.7730225324630737\n",
      "epoch  146  time: 27.636131048202515\n",
      "gen_loss: -5.308830261230469  disc_loss: 6.896095275878906\n",
      "epoch  147  time: 27.667145252227783\n",
      "gen_loss: -5.811177730560303  disc_loss: 7.058151721954346\n",
      "epoch  148  time: 34.35395693778992                            best_score\n",
      "gen_loss: 1.3723411560058594  disc_loss: 3.4349217414855957\n",
      "epoch  149  time: 27.67960286140442\n",
      "gen_loss: -5.985396385192871  disc_loss: 7.190377712249756\n",
      "epoch  150  time: 27.641186475753784\n",
      "gen_loss: -2.846576690673828  disc_loss: 4.357152938842773\n",
      "epoch  151  time: 27.632534980773926\n",
      "gen_loss: -4.2814040184021  disc_loss: 5.423646450042725\n",
      "epoch  152  time: 34.0759220123291                            best_score\n",
      "gen_loss: 0.735174834728241  disc_loss: 3.815746307373047\n",
      "epoch  153  time: 27.67913579940796\n",
      "gen_loss: -3.2911534309387207  disc_loss: 5.012216091156006\n",
      "epoch  154  time: 27.624502420425415\n",
      "gen_loss: 2.3227343559265137  disc_loss: 0.5312545895576477\n",
      "epoch  155  time: 27.6501784324646\n",
      "gen_loss: -4.026742458343506  disc_loss: 5.227293968200684\n",
      "epoch  156  time: 27.64660406112671\n",
      "gen_loss: 4.637235641479492  disc_loss: 0.16744545102119446\n",
      "epoch  157  time: 27.655839681625366\n",
      "gen_loss: 4.586942672729492  disc_loss: 0.05060766264796257\n",
      "epoch  158  time: 27.655189275741577\n",
      "gen_loss: -1.019992470741272  disc_loss: 2.2354774475097656\n",
      "epoch  159  time: 27.666438102722168\n",
      "gen_loss: 0.8892926573753357  disc_loss: 1.0695246458053589\n",
      "epoch  160  time: 27.657352447509766\n",
      "gen_loss: 2.665480852127075  disc_loss: 0.3696002662181854\n",
      "epoch  161  time: 27.656558990478516\n",
      "gen_loss: 1.7524213790893555  disc_loss: 2.0136001110076904\n",
      "epoch  162  time: 27.645968914031982\n",
      "gen_loss: 3.531770706176758  disc_loss: 0.17556247115135193\n",
      "epoch  163  time: 27.64066195487976\n",
      "gen_loss: -4.255990505218506  disc_loss: 5.546452045440674\n",
      "epoch  164  time: 27.650286197662354\n",
      "gen_loss: -1.630792498588562  disc_loss: 4.200885772705078\n",
      "epoch  165  time: 34.49936556816101                            best_score\n",
      "gen_loss: 0.262834757566452  disc_loss: 2.1699740886688232\n",
      "epoch  166  time: 27.710090398788452\n",
      "gen_loss: -2.5387773513793945  disc_loss: 3.6052279472351074\n",
      "epoch  167  time: 27.60871458053589\n",
      "gen_loss: -1.142404556274414  disc_loss: 2.3387467861175537\n",
      "epoch  168  time: 27.621173620224\n",
      "gen_loss: 2.0889954566955566  disc_loss: 0.4528946876525879\n",
      "epoch  169  time: 27.653138160705566\n",
      "gen_loss: -0.40163615345954895  disc_loss: 2.864410638809204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  170  time: 27.614972591400146\n",
      "gen_loss: -2.378391742706299  disc_loss: 3.5521368980407715\n",
      "epoch  171  time: 27.6397442817688\n",
      "gen_loss: 0.8597792983055115  disc_loss: 1.595458984375\n",
      "epoch  172  time: 27.63205122947693\n",
      "gen_loss: -0.8116487264633179  disc_loss: 2.075148105621338\n",
      "epoch  173  time: 27.661365509033203\n",
      "gen_loss: -1.1731431484222412  disc_loss: 2.90425705909729\n",
      "epoch  174  time: 27.658432245254517\n",
      "gen_loss: 0.38827553391456604  disc_loss: 0.9659926295280457\n",
      "epoch  175  time: 27.66253423690796\n",
      "gen_loss: -2.046321392059326  disc_loss: 3.2414987087249756\n",
      "epoch  176  time: 34.346863985061646                            best_score\n",
      "gen_loss: -0.005137347150593996  disc_loss: 1.5268887281417847\n",
      "epoch  177  time: 27.70219874382019\n",
      "gen_loss: 0.07292218506336212  disc_loss: 1.6616538763046265\n",
      "epoch  178  time: 27.61740493774414\n",
      "gen_loss: 0.4646854102611542  disc_loss: 1.6723352670669556\n",
      "epoch  179  time: 27.66045641899109\n",
      "gen_loss: -0.14821559190750122  disc_loss: 1.6359939575195312\n",
      "epoch  180  time: 27.655718564987183\n",
      "gen_loss: -0.17205822467803955  disc_loss: 1.5625615119934082\n",
      "epoch  181  time: 27.64783215522766\n",
      "gen_loss: 1.0145456790924072  disc_loss: 0.7004879713058472\n",
      "epoch  182  time: 27.65257716178894\n",
      "gen_loss: 11.801724433898926  disc_loss: 0.28770145773887634\n",
      "epoch  183  time: 27.608294010162354\n",
      "gen_loss: 3.845853328704834  disc_loss: 0.10626561939716339\n",
      "epoch  184  time: 27.650455236434937\n",
      "gen_loss: 2.772521734237671  disc_loss: 0.4022082984447479\n",
      "epoch  185  time: 27.65824556350708\n",
      "gen_loss: 1.0694829225540161  disc_loss: 0.4113759696483612\n",
      "epoch  186  time: 27.65290117263794\n",
      "gen_loss: 2.0545339584350586  disc_loss: 0.22503410279750824\n",
      "epoch  187  time: 27.627580165863037\n",
      "gen_loss: 2.6985812187194824  disc_loss: 0.1731012612581253\n",
      "epoch  188  time: 27.668088674545288\n",
      "gen_loss: 2.4885451793670654  disc_loss: 0.30374473333358765\n",
      "epoch  189  time: 27.63106417655945\n",
      "gen_loss: 3.801547050476074  disc_loss: 0.12493601441383362\n",
      "epoch  190  time: 27.674112558364868\n",
      "gen_loss: 1.7639992237091064  disc_loss: 0.23929229378700256\n",
      "epoch  191  time: 27.670618057250977\n",
      "gen_loss: 9.823424339294434  disc_loss: 0.18672698736190796\n",
      "epoch  192  time: 27.663210153579712\n",
      "gen_loss: 0.9226285219192505  disc_loss: 0.740998387336731\n",
      "epoch  193  time: 27.634148836135864\n",
      "gen_loss: 3.3059279918670654  disc_loss: 0.28159743547439575\n",
      "epoch  194  time: 27.643250226974487\n",
      "gen_loss: 1.1149110794067383  disc_loss: 0.3408180773258209\n",
      "epoch  195  time: 27.65992760658264\n",
      "gen_loss: 1.8592830896377563  disc_loss: 0.2161460965871811\n",
      "epoch  196  time: 27.622382640838623\n",
      "gen_loss: 1.3623542785644531  disc_loss: 0.4555206894874573\n",
      "epoch  197  time: 27.63758397102356\n",
      "gen_loss: 10.112314224243164  disc_loss: 0.07839246094226837\n",
      "epoch  198  time: 27.65803861618042\n",
      "gen_loss: 1.2884217500686646  disc_loss: 0.26505592465400696\n",
      "epoch  199  time: 27.644299507141113\n",
      "gen_loss: 1.9919323921203613  disc_loss: 0.15507841110229492\n",
      "epoch  200  time: 27.65372347831726\n",
      "gen_loss: 2.459042549133301  disc_loss: 0.3151950240135193\n",
      "epoch  201  time: 27.608241319656372\n",
      "gen_loss: 4.207663536071777  disc_loss: 0.042114753276109695\n",
      "epoch  202  time: 27.589139223098755\n",
      "gen_loss: 3.352332592010498  disc_loss: 0.11157725751399994\n",
      "epoch  203  time: 27.60794186592102\n",
      "gen_loss: 4.2471771240234375  disc_loss: 0.11867332458496094\n",
      "epoch  204  time: 27.623167514801025\n",
      "gen_loss: 3.832003593444824  disc_loss: 0.07687607407569885\n",
      "epoch  205  time: 27.695151329040527\n",
      "gen_loss: 6.615918159484863  disc_loss: 0.01741703413426876\n",
      "epoch  206  time: 27.633036851882935\n",
      "gen_loss: 3.052645683288574  disc_loss: 0.13889436423778534\n",
      "epoch  207  time: 27.61308264732361\n",
      "gen_loss: 3.6682536602020264  disc_loss: 0.07202843576669693\n",
      "epoch  208  time: 27.657206296920776\n",
      "gen_loss: 3.9809303283691406  disc_loss: 0.057149872183799744\n",
      "epoch  209  time: 27.663415908813477\n",
      "gen_loss: 3.5376968383789062  disc_loss: 0.38088786602020264\n",
      "epoch  210  time: 27.62742280960083\n",
      "gen_loss: 15.800308227539062  disc_loss: 0.07666979730129242\n",
      "epoch  211  time: 27.65524411201477\n",
      "gen_loss: 3.9017767906188965  disc_loss: 0.0780668631196022\n",
      "epoch  212  time: 27.660585641860962\n",
      "gen_loss: 2.4479377269744873  disc_loss: 0.027963999658823013\n",
      "epoch  213  time: 27.635557174682617\n",
      "gen_loss: 3.0761663913726807  disc_loss: 0.025028055533766747\n",
      "epoch  214  time: 27.640578031539917\n",
      "gen_loss: 10.337224960327148  disc_loss: 0.028795791789889336\n",
      "epoch  215  time: 27.65128517150879\n",
      "gen_loss: 2.9571893215179443  disc_loss: 0.09322109073400497\n",
      "epoch  216  time: 27.638716220855713\n",
      "gen_loss: 3.265514850616455  disc_loss: 0.04080156236886978\n",
      "epoch  217  time: 27.642578840255737\n",
      "gen_loss: 11.793596267700195  disc_loss: 0.04578227177262306\n",
      "epoch  218  time: 27.618109464645386\n",
      "gen_loss: 2.2942535877227783  disc_loss: 0.1202675923705101\n",
      "epoch  219  time: 27.649667739868164\n",
      "gen_loss: 3.9100005626678467  disc_loss: 0.040614668279886246\n",
      "epoch  220  time: 27.654901266098022\n",
      "gen_loss: 3.314955949783325  disc_loss: 0.07553206384181976\n",
      "epoch  221  time: 27.650806427001953\n",
      "gen_loss: 2.833085536956787  disc_loss: 0.04261550307273865\n",
      "epoch  222  time: 27.660446405410767\n",
      "gen_loss: 9.253701210021973  disc_loss: 0.03669338673353195\n",
      "epoch  223  time: 27.639079093933105\n",
      "gen_loss: 3.1963627338409424  disc_loss: 0.03361767530441284\n",
      "epoch  224  time: 27.655261754989624\n",
      "gen_loss: 3.6696717739105225  disc_loss: 0.018189292401075363\n",
      "epoch  225  time: 27.636324644088745\n",
      "gen_loss: 13.033631324768066  disc_loss: 0.07200825959444046\n",
      "epoch  226  time: 27.641874313354492\n",
      "gen_loss: 4.191493988037109  disc_loss: 0.03390350937843323\n",
      "epoch  227  time: 27.635297060012817\n",
      "gen_loss: 3.755612373352051  disc_loss: 0.02813839353621006\n",
      "epoch  228  time: 27.644962310791016\n",
      "gen_loss: 3.6980514526367188  disc_loss: 0.02313661016523838\n",
      "epoch  229  time: 27.660998582839966\n",
      "gen_loss: 5.162583351135254  disc_loss: 0.021563120186328888\n",
      "epoch  230  time: 27.649562120437622\n",
      "gen_loss: 4.409828186035156  disc_loss: 0.010772150941193104\n",
      "epoch  231  time: 27.62527298927307\n",
      "gen_loss: 3.374440908432007  disc_loss: 0.0621965229511261\n",
      "epoch  232  time: 27.640888929367065\n",
      "gen_loss: 7.711228370666504  disc_loss: 0.05784382298588753\n",
      "epoch  233  time: 27.65348529815674\n",
      "gen_loss: 8.480424880981445  disc_loss: 0.019452443346381187\n",
      "epoch  234  time: 27.65530300140381\n",
      "gen_loss: 3.6897130012512207  disc_loss: 0.0008171646040864289\n",
      "epoch  235  time: 27.642244815826416\n",
      "gen_loss: 7.807063102722168  disc_loss: 0.00043944877688772976\n",
      "epoch  236  time: 27.657511472702026\n",
      "gen_loss: 6.155423164367676  disc_loss: 0.033441897481679916\n",
      "epoch  237  time: 27.65772247314453\n",
      "gen_loss: 3.711200714111328  disc_loss: 0.025057341903448105\n",
      "epoch  238  time: 27.64307975769043\n",
      "gen_loss: 7.9686737060546875  disc_loss: 0.0199370626360178\n",
      "epoch  239  time: 27.633527278900146\n",
      "gen_loss: 17.675722122192383  disc_loss: 0.026230094954371452\n",
      "epoch  240  time: 27.655938386917114\n",
      "gen_loss: 2.9277467727661133  disc_loss: 0.0031245958525687456\n",
      "epoch  241  time: 27.626245260238647\n",
      "gen_loss: 10.14974594116211  disc_loss: 0.009138213470578194\n",
      "epoch  242  time: 27.66127109527588\n",
      "gen_loss: 3.5224721431732178  disc_loss: 0.012051736004650593\n",
      "epoch  243  time: 27.66019368171692\n",
      "gen_loss: 4.026473522186279  disc_loss: 0.0\n",
      "epoch  244  time: 27.665406942367554\n",
      "gen_loss: 8.822007179260254  disc_loss: 0.0\n",
      "epoch  245  time: 27.643505096435547\n",
      "gen_loss: 5.463111877441406  disc_loss: 0.01068152580410242\n",
      "epoch  246  time: 27.6304292678833\n",
      "gen_loss: 2.18559193611145  disc_loss: 0.019783327355980873\n",
      "epoch  247  time: 27.64190649986267\n",
      "gen_loss: 3.310941219329834  disc_loss: 0.00736718624830246\n",
      "epoch  248  time: 27.657238006591797\n",
      "gen_loss: 3.6409130096435547  disc_loss: 0.004700370132923126\n",
      "epoch  249  time: 27.65292501449585\n",
      "gen_loss: 2.2253942489624023  disc_loss: 0.013157298788428307\n",
      "epoch  250  time: 27.619410276412964\n",
      "gen_loss: 3.960533618927002  disc_loss: 0.00783049501478672\n",
      "epoch  251  time: 27.646971225738525\n",
      "gen_loss: 5.4337239265441895  disc_loss: 0.0028524482622742653\n",
      "epoch  252  time: 27.645193338394165\n",
      "gen_loss: 4.255845546722412  disc_loss: 0.004598665051162243\n",
      "epoch  253  time: 27.652321338653564\n",
      "gen_loss: 6.320974826812744  disc_loss: 0.01339589711278677\n",
      "epoch  254  time: 27.67334270477295\n",
      "gen_loss: 14.066154479980469  disc_loss: 0.005039028823375702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  255  time: 27.639671564102173\n",
      "gen_loss: 3.2960853576660156  disc_loss: 0.006195093505084515\n",
      "epoch  256  time: 27.652669191360474\n",
      "gen_loss: 2.903109073638916  disc_loss: 0.01122379582375288\n",
      "epoch  257  time: 27.634041786193848\n",
      "gen_loss: 4.398645877838135  disc_loss: 0.016270138323307037\n",
      "epoch  258  time: 27.64151954650879\n",
      "gen_loss: 2.8086559772491455  disc_loss: 0.0035988008603453636\n",
      "epoch  259  time: 27.646209955215454\n",
      "gen_loss: 13.262228012084961  disc_loss: 0.020983869209885597\n",
      "epoch  260  time: 27.65987277030945\n",
      "gen_loss: 2.1472530364990234  disc_loss: 0.04678035527467728\n",
      "epoch  261  time: 27.64308261871338\n",
      "gen_loss: 12.157798767089844  disc_loss: 0.0023747978266328573\n",
      "epoch  262  time: 27.637582540512085\n",
      "gen_loss: 3.020536184310913  disc_loss: 0.0\n",
      "epoch  263  time: 27.633057355880737\n",
      "gen_loss: 4.344814300537109  disc_loss: 0.009663413278758526\n",
      "epoch  264  time: 27.65693688392639\n",
      "gen_loss: 8.117682456970215  disc_loss: 0.0048879398964345455\n",
      "epoch  265  time: 27.6518075466156\n",
      "gen_loss: 4.971062660217285  disc_loss: 0.0031938233878463507\n",
      "epoch  266  time: 27.614237070083618\n",
      "gen_loss: 3.1468799114227295  disc_loss: 0.03005230613052845\n",
      "epoch  267  time: 27.64038872718811\n",
      "gen_loss: 2.692732334136963  disc_loss: 0.0102597801014781\n",
      "epoch  268  time: 27.65475082397461\n",
      "gen_loss: 3.7810394763946533  disc_loss: 0.06391876935958862\n",
      "epoch  269  time: 27.629249095916748\n",
      "gen_loss: 3.2664833068847656  disc_loss: 0.007593346759676933\n",
      "epoch  270  time: 27.631943464279175\n",
      "gen_loss: 4.2242255210876465  disc_loss: 0.0177043117582798\n",
      "epoch  271  time: 27.6484055519104\n",
      "gen_loss: 11.934148788452148  disc_loss: 0.0\n",
      "epoch  272  time: 27.66746234893799\n",
      "gen_loss: 6.578217029571533  disc_loss: 0.0015721761155873537\n",
      "epoch  273  time: 27.64280104637146\n",
      "gen_loss: 5.018779754638672  disc_loss: 0.025894397869706154\n",
      "epoch  274  time: 27.610546588897705\n",
      "gen_loss: 4.449915409088135  disc_loss: 0.002690583234652877\n",
      "epoch  275  time: 27.641708374023438\n",
      "gen_loss: 2.1774702072143555  disc_loss: 0.030960431322455406\n",
      "epoch  276  time: 27.65122151374817\n",
      "gen_loss: 5.509902000427246  disc_loss: 0.0\n",
      "epoch  277  time: 27.667428970336914\n",
      "gen_loss: 10.661534309387207  disc_loss: 0.0\n",
      "epoch  278  time: 27.655561447143555\n",
      "gen_loss: 13.229019165039062  disc_loss: 0.0015647965483367443\n",
      "epoch  279  time: 27.65709352493286\n",
      "gen_loss: 8.462944030761719  disc_loss: 0.0\n",
      "epoch  280  time: 27.63137412071228\n",
      "gen_loss: 5.138132572174072  disc_loss: 0.0\n",
      "epoch  281  time: 27.662989854812622\n",
      "gen_loss: 5.600592613220215  disc_loss: 0.010567481629550457\n",
      "epoch  282  time: 27.653414726257324\n",
      "gen_loss: 7.086358547210693  disc_loss: 0.0\n",
      "epoch  283  time: 27.654974222183228\n",
      "gen_loss: 4.1411590576171875  disc_loss: 0.0008270788821391761\n",
      "epoch  284  time: 27.62372136116028\n",
      "gen_loss: 4.572880744934082  disc_loss: 0.0\n",
      "epoch  285  time: 27.636579990386963\n",
      "gen_loss: 5.15049934387207  disc_loss: 0.01467856578528881\n",
      "epoch  286  time: 27.631255388259888\n",
      "gen_loss: 3.9163589477539062  disc_loss: 0.028802022337913513\n",
      "epoch  287  time: 27.63531756401062\n",
      "gen_loss: 3.567394733428955  disc_loss: 0.003995601087808609\n",
      "epoch  288  time: 27.62770128250122\n",
      "gen_loss: 3.719228744506836  disc_loss: 0.007773787714540958\n",
      "epoch  289  time: 27.64578938484192\n",
      "gen_loss: 4.162768363952637  disc_loss: 0.006215181201696396\n",
      "epoch  290  time: 27.62203049659729\n",
      "gen_loss: 3.8389344215393066  disc_loss: 0.010467306710779667\n",
      "epoch  291  time: 27.645707845687866\n",
      "gen_loss: 4.0650811195373535  disc_loss: 0.0\n",
      "epoch  292  time: 27.650811195373535\n",
      "gen_loss: 9.980765342712402  disc_loss: 0.0\n",
      "epoch  293  time: 27.628799200057983\n",
      "gen_loss: 7.169902801513672  disc_loss: 0.0\n",
      "epoch  294  time: 27.6323983669281\n",
      "gen_loss: 4.151661396026611  disc_loss: 0.0\n",
      "epoch  295  time: 27.625964641571045\n",
      "gen_loss: 4.85202169418335  disc_loss: 0.0\n",
      "epoch  296  time: 27.636358737945557\n",
      "gen_loss: 7.328830242156982  disc_loss: 0.03322857245802879\n",
      "epoch  297  time: 27.639979600906372\n",
      "gen_loss: 2.5363988876342773  disc_loss: 0.014371419325470924\n",
      "epoch  298  time: 27.641053915023804\n",
      "gen_loss: 3.2762303352355957  disc_loss: 0.04140796139836311\n",
      "epoch  299  time: 27.644124269485474\n",
      "gen_loss: 4.013339042663574  disc_loss: 0.006637184880673885\n",
      "epoch  300  time: 27.653196334838867\n",
      "gen_loss: 4.054476737976074  disc_loss: 0.0\n",
      "epoch  301  time: 27.64560604095459\n",
      "gen_loss: 4.29434871673584  disc_loss: 0.0\n",
      "epoch  302  time: 27.636217832565308\n",
      "gen_loss: 6.311338901519775  disc_loss: 0.0\n",
      "epoch  303  time: 27.644630908966064\n",
      "gen_loss: 5.63479471206665  disc_loss: 0.014162369072437286\n",
      "epoch  304  time: 27.64353346824646\n",
      "gen_loss: 8.140120506286621  disc_loss: 0.0\n",
      "epoch  305  time: 27.66826605796814\n",
      "gen_loss: 11.923290252685547  disc_loss: 0.0\n",
      "epoch  306  time: 27.650192260742188\n",
      "gen_loss: 4.48057222366333  disc_loss: 0.0\n",
      "epoch  307  time: 27.645683526992798\n",
      "gen_loss: 3.866884708404541  disc_loss: 0.006214193534106016\n",
      "epoch  308  time: 27.648919820785522\n",
      "gen_loss: 5.6685004234313965  disc_loss: 9.294952906202525e-05\n",
      "epoch  309  time: 27.6363844871521\n",
      "gen_loss: 3.3666279315948486  disc_loss: 0.0\n",
      "epoch  310  time: 27.626763820648193\n",
      "gen_loss: 3.142690896987915  disc_loss: 0.0\n",
      "epoch  311  time: 27.64648461341858\n",
      "gen_loss: 14.810603141784668  disc_loss: 0.0\n",
      "epoch  312  time: 27.65031361579895\n",
      "gen_loss: 3.3916239738464355  disc_loss: 0.0\n",
      "epoch  313  time: 27.653585195541382\n",
      "gen_loss: 4.236280918121338  disc_loss: 0.0\n",
      "epoch  314  time: 27.636269092559814\n",
      "gen_loss: 3.2977588176727295  disc_loss: 0.0\n",
      "epoch  315  time: 27.655856609344482\n",
      "gen_loss: 10.353171348571777  disc_loss: 0.010470821522176266\n",
      "epoch  316  time: 27.642149209976196\n",
      "gen_loss: 5.415169715881348  disc_loss: 0.0\n",
      "epoch  317  time: 27.6424880027771\n",
      "gen_loss: 4.618157863616943  disc_loss: 0.0\n",
      "epoch  318  time: 27.65358304977417\n",
      "gen_loss: 7.575259208679199  disc_loss: 0.0004030815325677395\n",
      "epoch  319  time: 27.635961055755615\n",
      "gen_loss: 9.237918853759766  disc_loss: 0.010592800565063953\n",
      "epoch  320  time: 27.62428879737854\n",
      "gen_loss: 5.5056233406066895  disc_loss: 0.004708828404545784\n",
      "epoch  321  time: 27.59560251235962\n",
      "gen_loss: 4.483046531677246  disc_loss: 0.00529272248968482\n",
      "epoch  322  time: 27.63006854057312\n",
      "gen_loss: 3.984388828277588  disc_loss: 0.02202450856566429\n",
      "epoch  323  time: 27.637958526611328\n",
      "gen_loss: 4.700742244720459  disc_loss: 0.0\n",
      "epoch  324  time: 27.655527353286743\n",
      "gen_loss: 4.048886299133301  disc_loss: 0.0004936456680297852\n",
      "epoch  325  time: 27.633161306381226\n",
      "gen_loss: 5.347434997558594  disc_loss: 0.0\n",
      "epoch  326  time: 27.646158695220947\n",
      "gen_loss: 3.5261082649230957  disc_loss: 0.006826349068433046\n",
      "epoch  327  time: 27.648521184921265\n",
      "gen_loss: 3.6115689277648926  disc_loss: 0.0\n",
      "epoch  328  time: 27.64215636253357\n",
      "gen_loss: 4.359132289886475  disc_loss: 0.0\n",
      "epoch  329  time: 27.639872550964355\n",
      "gen_loss: 5.41895866394043  disc_loss: 0.0\n",
      "epoch  330  time: 27.62078285217285\n",
      "gen_loss: 4.982885360717773  disc_loss: 0.0\n",
      "epoch  331  time: 27.614607572555542\n",
      "gen_loss: 3.8341495990753174  disc_loss: 0.0\n",
      "epoch  332  time: 27.629934787750244\n",
      "gen_loss: 10.316991806030273  disc_loss: 0.00016127331764437258\n",
      "epoch  333  time: 27.655550956726074\n",
      "gen_loss: 4.1422648429870605  disc_loss: 0.002223297720775008\n",
      "epoch  334  time: 27.643564224243164\n",
      "gen_loss: 2.695615291595459  disc_loss: 0.005704811308532953\n",
      "epoch  335  time: 27.640504837036133\n",
      "gen_loss: 3.9616665840148926  disc_loss: 0.0\n",
      "epoch  336  time: 27.5967059135437\n",
      "gen_loss: 5.989431858062744  disc_loss: 0.0\n",
      "epoch  337  time: 27.65370225906372\n",
      "gen_loss: 4.572512149810791  disc_loss: 0.0\n",
      "epoch  338  time: 27.651212215423584\n",
      "gen_loss: 5.9336256980896  disc_loss: 0.004224064294248819\n",
      "epoch  339  time: 27.605172634124756\n",
      "gen_loss: 5.102719306945801  disc_loss: 0.0\n",
      "epoch  340  time: 27.647122383117676\n",
      "gen_loss: 2.938821792602539  disc_loss: 0.0\n",
      "epoch  341  time: 27.636330604553223\n",
      "gen_loss: 6.499215126037598  disc_loss: 0.0\n",
      "epoch  342  time: 27.63208556175232\n",
      "gen_loss: 5.430887699127197  disc_loss: 0.0017685920465737581\n",
      "epoch  343  time: 27.64113187789917\n",
      "gen_loss: 14.969622611999512  disc_loss: 0.0\n",
      "epoch  344  time: 27.611124515533447\n",
      "gen_loss: 3.2930822372436523  disc_loss: 0.003016009461134672\n",
      "epoch  345  time: 27.637065410614014\n",
      "gen_loss: 2.650928497314453  disc_loss: 0.07373613119125366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  346  time: 27.672014474868774\n",
      "gen_loss: 3.499380350112915  disc_loss: 0.0035578145179897547\n",
      "epoch  347  time: 27.649213552474976\n",
      "gen_loss: 17.206308364868164  disc_loss: 0.010165250860154629\n",
      "epoch  348  time: 27.615474224090576\n",
      "gen_loss: 12.399907112121582  disc_loss: 0.0\n",
      "epoch  349  time: 27.62813639640808\n",
      "gen_loss: 2.421959400177002  disc_loss: 0.0\n",
      "epoch  350  time: 27.63051199913025\n",
      "gen_loss: 5.54001522064209  disc_loss: 0.0\n",
      "epoch  351  time: 27.632538557052612\n",
      "gen_loss: 5.569363117218018  disc_loss: 0.004131276160478592\n",
      "epoch  352  time: 27.640827894210815\n",
      "gen_loss: 6.010631084442139  disc_loss: 0.007906820625066757\n",
      "epoch  353  time: 27.661545038223267\n",
      "gen_loss: 5.525917053222656  disc_loss: 0.0\n",
      "epoch  354  time: 27.65675663948059\n",
      "gen_loss: 7.097745418548584  disc_loss: 0.0\n",
      "epoch  355  time: 27.622708082199097\n",
      "gen_loss: 9.360835075378418  disc_loss: 0.0\n",
      "epoch  356  time: 27.620652198791504\n",
      "gen_loss: 18.015949249267578  disc_loss: 0.009391448460519314\n",
      "epoch  357  time: 27.643568515777588\n",
      "gen_loss: 3.507486581802368  disc_loss: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2153bcc8a4de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-c9a01002a975>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs, lenght, loss_range)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_step_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_step_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mdisc_loss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mgen_loss_\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/tf_gpu/tf_gpu_env/lib/python3.5/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs=5000\n",
    "train(dataset,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10722 /10723\n",
      "aprioriing data\n",
      "total_data_long: 107230\n",
      "time: 1.5s\n",
      "time: 4.9s\n",
      "showing data\n",
      "n=1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse= 11448.311971640185\n",
      "cos 0.9190154180468325\n",
      "pccs (-0.24229544380608406, 1.5242740695376978e-07)\n",
      "n= 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse= 9060.221686029543\n",
      "cos 1.0\n",
      "pccs (-0.253240871363627, 2.4352490075460645e-20)\n",
      "aprioriing data\n",
      "total_data_long: 321690\n",
      "time: 35.14s\n",
      "time: 4.38s\n",
      "showing data\n",
      "n=1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFIJJREFUeJzt3X+MZeV93/H3J6yNW6eFxWxXdBd3ibyyRSrZRiNY5KhKoVkwjQJ/IAsrCiu61f5DWqdKlUL7B4odKbFUhRipQUGGZG25xpQ4BSFkulkj5R8bM1tczA/DjnEwuwJ2wwJpY8kJzrd/3Gfger2ze+/Mnbl35nm/pNGc85znnvs899w5n3Oec+6dVBWSpD79zLQbIEmaHkNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1LFN027A6Zx//vm1Y8eOaTdDktaVQ4cO/VVVbRml7kyHwI4dO5ifn592MyRpXUny4qh1HQ6SpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUsdGCoEk5ya5P8l3kzyb5PIk5yU5kORw+7251U2SO5IsJHkyySVD69nT6h9Osme1OiVJGs2oZwKfA75WVR8CPgw8C9wCHKyqncDBNg/wcWBn+9kH3AmQ5DzgNuAy4FLgtsXgkCRNxxlDIMk5wL8A7gaoqr+tqjeAa4H9rdp+4Lo2fS3whRr4JnBukguAq4ADVXWiql4HDgBXT7Q3kqSxjHImcBFwHPjjJE8k+XyS9wJbq+rlVucVYGub3ga8NPT4I61sqXJJ0pSMEgKbgEuAO6vqo8Df8M7QDwBVVUBNokFJ9iWZTzJ//PjxSaxSkrSEUULgCHCkqh5r8/czCIVX2zAP7fextvwocOHQ47e3sqXKf0JV3VVVc1U1t2XLSP8dTZK0TGcMgap6BXgpyQdb0ZXAM8CDwOIdPnuAB9r0g8CN7S6hXcCbbdjoEWB3ks3tgvDuViZJmpJR/8fwvwO+lOTdwAvATQwC5L4ke4EXgU+0ug8D1wALwA9bXarqRJLPAI+3ep+uqhMT6YUkaVkyGM6fTXNzc+U/mpek8SQ5VFVzo9T1E8OS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOjRQCSf4yyXeSfDvJfCs7L8mBJIfb782tPEnuSLKQ5MkklwytZ0+rfzjJntXpkiRpVOOcCfzLqvpIVc21+VuAg1W1EzjY5gE+DuxsP/uAO2EQGsBtwGXApcBti8EhSZqOlQwHXQvsb9P7geuGyr9QA98Ezk1yAXAVcKCqTlTV68AB4OoVPL8kaYVGDYEC/leSQ0n2tbKtVfVym34F2NqmtwEvDT32SCtbqlySNCWbRqz3C1V1NMk/AQ4k+e7wwqqqJDWJBrWQ2Qfw/ve/fxKrlCQtYaQzgao62n4fA/6MwZj+q22Yh/b7WKt+FLhw6OHbW9lS5Sc/111VNVdVc1u2bBmvN5KksZwxBJK8N8k/WpwGdgNPAQ8Ci3f47AEeaNMPAje2u4R2AW+2YaNHgN1JNrcLwrtbmSRpSkYZDtoK/FmSxfr/vaq+luRx4L4ke4EXgU+0+g8D1wALwA+BmwCq6kSSzwCPt3qfrqoTE+uJJGlsqZrIUP6qmJubq/n5+Wk3Q5LWlSSHhm7nPy0/MSxJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHRs5BJKcleSJJA+1+YuSPJZkIclXkry7lZ/d5hfa8h1D67i1lT+X5KpJd0aSNJ5xzgQ+BTw7NP9Z4Paq+gDwOrC3le8FXm/lt7d6JLkYuAH4eeBq4A+TnLWy5kuSVmKkEEiyHfjXwOfbfIArgPtblf3AdW362jZPW35lq38tcG9V/aiqvg8sAJdOohOSpOUZ9UzgD4DfAv6+zb8PeKOq3mrzR4BtbXob8BJAW/5mq/92+Ske87Yk+5LMJ5k/fvz4GF2RJI3rjCGQ5JeBY1V1aA3aQ1XdVVVzVTW3ZcuWtXhKSerWphHqfAz4lSTXAO8B/jHwOeDcJJva0f524GirfxS4EDiSZBNwDvDaUPmi4cdIkqbgjGcCVXVrVW2vqh0MLux+vap+FXgUuL5V2wM80KYfbPO05V+vqmrlN7S7hy4CdgLfmlhPJEljG+VMYCn/Cbg3ye8ATwB3t/K7gS8mWQBOMAgOqurpJPcBzwBvATdX1Y9X8PySpBXK4CB9Ns3NzdX8/Py0myFJ60qSQ1U1N0pdPzEsSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnq2BlDIMl7knwryf9J8nSS327lFyV5LMlCkq8keXcrP7vNL7TlO4bWdWsrfy7JVavVKUnSaEY5E/gRcEVVfRj4CHB1kl3AZ4Hbq+oDwOvA3lZ/L/B6K7+91SPJxcANwM8DVwN/mOSsSXZGkjSeM4ZADfy/Nvuu9lPAFcD9rXw/cF2bvrbN05ZfmSSt/N6q+lFVfR9YAC6dSC8kScsy0jWBJGcl+TZwDDgAfA94o6realWOANva9DbgJYC2/E3gfcPlp3iMJGkKRgqBqvpxVX0E2M7g6P1Dq9WgJPuSzCeZP378+Go9jSSJMe8Oqqo3gEeBy4Fzk2xqi7YDR9v0UeBCgLb8HOC14fJTPGb4Oe6qqrmqmtuyZcs4zZMkjWmUu4O2JDm3Tf8D4JeAZxmEwfWt2h7ggTb9YJunLf96VVUrv6HdPXQRsBP41qQ6Ikka36YzV+ECYH+7k+dngPuq6qEkzwD3Jvkd4Ang7lb/buCLSRaAEwzuCKKqnk5yH/AM8BZwc1X9eLLdkSSNI4OD9Nk0NzdX8/Pz026GJK0rSQ5V1dwodf3EsCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWNnDIEkFyZ5NMkzSZ5O8qlWfl6SA0kOt9+bW3mS3JFkIcmTSS4ZWteeVv9wkj2r1y1J0ihGORN4C/jNqroY2AXcnORi4BbgYFXtBA62eYCPAzvbzz7gThiEBnAbcBlwKXDbYnBIkqbjjCFQVS9X1f9u0/8XeBbYBlwL7G/V9gPXtelrgS/UwDeBc5NcAFwFHKiqE1X1OnAAuHqivZEkjWWsawJJdgAfBR4DtlbVy23RK8DWNr0NeGnoYUda2VLlkqQpGTkEkvws8KfAb1TVXw8vq6oCahINSrIvyXyS+ePHj09ilZKkJYwUAknexSAAvlRVX23Fr7ZhHtrvY638KHDh0MO3t7Klyn9CVd1VVXNVNbdly5Zx+iJJGtModwcFuBt4tqp+f2jRg8DiHT57gAeGym9sdwntAt5sw0aPALuTbG4XhHe3MknSlGwaoc7HgF8DvpPk263sPwO/B9yXZC/wIvCJtuxh4BpgAfghcBNAVZ1I8hng8Vbv01V1YiK9kCQtSwbD+bNpbm6u5ufnp90MSVpXkhyqqrlR6vqJYUnqmCGwwd1+4PlpN0HSDDMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZAmvM//kraZYYApLUMUNAkjpmCEg9e/R3p90CTdkZQyDJPUmOJXlqqOy8JAeSHG6/N7fyJLkjyUKSJ5NcMvSYPa3+4SR7Vqc7kqRxjHIm8CfA1SeV3QIcrKqdwME2D/BxYGf72QfcCYPQAG4DLgMuBW5bDA5J0vScMQSq6i+AEycVXwvsb9P7geuGyr9QA98Ezk1yAXAVcKCqTlTV68ABfjpYJElrbLnXBLZW1ctt+hVga5veBrw0VO9IK1uq/Kck2ZdkPsn88ePHl9k8SdIoVnxhuKoKqAm0ZXF9d1XVXFXNbdmyZVKrldQDL3SPbbkh8Gob5qH9PtbKjwIXDtXb3sqWKtca8UNqkk5luSHwILB4h88e4IGh8hvbXUK7gDfbsNEjwO4km9sF4d2tTD3w6EyaWZvOVCHJl4FfBM5PcoTBXT6/B9yXZC/wIvCJVv1h4BpgAfghcBNAVZ1I8hng8Vbv01V18sVmSdIaO2MIVNUnl1h05SnqFnDzEuu5B7hnrNZJklaVnxiWpI4ZAit0qguuXoTVWLxmoikyBHRq7pikLhgCktQxQ0CSOmYIsI7G8McdonFIZza4HTSuNXzPGALrgTsRSavEENBkGFTSumQIrHfrZee7XtopQVfvV0NgDfhZghF19Ic3VdN8nd3GM8cQGOYbdP1xm60OX9duGAKzYNp/cNN+/lnga6BOGQJjcAhHE7PeQme9tXdUy+nXBnstugmBWdqBT7Mts/Q6rJoN9keq03Bbr9jGDoF18gb5xguvTWQ9XezgZ92sv+dmvX2L1ks7T3a6dp9q2Qz0c2OHwAq5U/1pviYzagZ2Jlqf+giBCfyBrNrOb0b/eCd1djKSGX0NZrZdWlsb/H2woUNgTXdk64xH9DNi3OGDtbBRd3qT7NfiujbAa7WhQ2DNjPBG+Mbd/3FVn3OcnfrE2zLrTt4+q/GHu9o7g1nc2YzappUG3Sz2fbVMoa8bPgRuP/D8RM8IVusIehLr3fWDu8Z/0CweiS7HWrR1Fl+PM7VpFj8dvNq3Zc7idhr26O/OVBs3fAjMunECaq2Ht4afb2Lht9I3/zQeP+pdHTN698fbJhkYk9zBr+Rxs2idfeV7fyGwgmGUYaMMqZxq3YtH66MctS/nO4dOXr7U8yzrrGGaVmvYYNyjspUMLc3YEeDbzrRDX+s2T2KYaS3bsdrrWGX9hcBShjbW7Qee/4md/PCO9XQ7z1PuoJf5Jjh5XeOse6zrA6c4uzhdwI0UHqu18xhe36hHopM6Yl0PO5zVXvepQmw1t/Hplo3Tjklu6+UcMMz4dY/uQuAbL7w2saGN2w88f8ad4jhDOIvtWulO/HTGDrFx6o56pDupP8pxhjdW4yh8uUfQozzuVDu8UUJwlOef1GOWWsekrEZQL/VarvR9uxp3Hq2RNQ+BJFcneS7JQpJb1vr5Fw0f7e76wV1844XXlj3mPomx89PtnE95tD7U3qWe80zLh+udrs6S4TTKH8+oO8pT/VFOaxhiVodt4MxHw9MaSlmqXeNOj/M8o9Qd9zrNOMG9nLOiGXxfrWkIJDkL+G/Ax4GLgU8muXgt2yBJesdanwlcCixU1QtV9bfAvcC1a9wGSVKz1iGwDXhpaP5IK5MkTUGqau2eLLkeuLqq/m2b/zXgsqr69aE6+4B9bfaDwHMreMrzgb9awePXK/vdF/vdl1H6/c+qassoK9u08vaM5Shw4dD89lb2tqq6C5jITexJ5qtqbhLrWk/sd1/sd18m3e+1Hg56HNiZ5KIk7wZuAB5c4zZIkpo1PROoqreS/DrwCHAWcE9VPb2WbZAkvWOth4OoqoeBh9fo6dbZdyNMjP3ui/3uy0T7vaYXhiVJs6W7r42QJL1jQ4bArHw1xWpIcmGSR5M8k+TpJJ9q5eclOZDkcPu9uZUnyR3ttXgyySXT7cHKJDkryRNJHmrzFyV5rPXvK+2GA5Kc3eYX2vId02z3SiQ5N8n9Sb6b5Nkkl/ewvZP8h/YefyrJl5O8Z6Nu7yT3JDmW5KmhsrG3cZI9rf7hJHtGee4NFwIdfDXFW8BvVtXFwC7g5ta/W4CDVbUTONjmYfA67Gw/+4A7177JE/Up4Nmh+c8Ct1fVB4DXgb2tfC/weiu/vdVbrz4HfK2qPgR8mEH/N/T2TrIN+PfAXFX9cwY3ktzAxt3efwJcfVLZWNs4yXnAbcBlDL6d4bbF4DitqtpQP8DlwCND87cCt067XavY3weAX2LwoboLWtkFwHNt+o+ATw7Vf7veevth8LmSg8AVwENAGHxoZtPJ257BHWiXt+lNrV6m3Ydl9Pkc4Psnt32jb2/e+XaB89r2ewi4aiNvb2AH8NRytzHwSeCPhsp/ot5SPxvuTICOvpqinfJ+FHgM2FpVL7dFrwBb2/RGej3+APgt4O/b/PuAN6rqrTY/3Le3+92Wv9nqrzcXAceBP27DYJ9P8l42+PauqqPAfwV+ALzMYPsdYuNv72HjbuNlbfuNGAJdSPKzwJ8Cv1FVfz28rAaHARvqtq8kvwwcq6pD027LGtsEXALcWVUfBf6Gd4YFgA27vTcz+HLJi4B/CryXnx4u6cZqbuONGAJn/GqK9S7JuxgEwJeq6qut+NUkF7TlFwDHWvlGeT0+BvxKkr9k8O2zVzAYKz83yeLnXYb79na/2/JzgLX9J82TcQQ4UlWPtfn7GYTCRt/e/wr4flUdr6q/A77K4D2w0bf3sHG38bK2/UYMgQ391RRJAtwNPFtVvz+06EFg8W6APQyuFSyW39juKNgFvDl0irluVNWtVbW9qnYw2KZfr6pfBR4Frm/VTu734utxfau/7o6Wq+oV4KUkH2xFVwLPsMG3N4NhoF1J/mF7zy/2e0Nv75OMu40fAXYn2dzOpHa3stOb9sWQVbrAcg3wPPA94L9Muz0T7tsvMDgtfBL4dvu5hsH450HgMPDnwHmtfhjcLfU94DsM7raYej9W+Br8IvBQm/454FvAAvA/gLNb+Xva/EJb/nPTbvcK+vsRYL5t8/8JbO5hewO/DXwXeAr4InD2Rt3ewJcZXPv4OwZnf3uXs42Bf9NegwXgplGe208MS1LHNuJwkCRpRIaAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkd+/8avySbwO6wdgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse= 13208.07389440262\n",
      "cos 0.830968946484692\n",
      "pccs (-0.10014583901983964, 0.0016955228712741068)\n",
      "n= 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse= 13046.309133237646\n",
      "cos 0.987687144199616\n",
      "pccs (-0.5289813327252633, 1.5695025868262553e-294)\n"
     ]
    }
   ],
   "source": [
    "def show_result(generator, decode_flag=True, useavg=True, avgbase=5, limit=1, bigest_num=10, cut=100, n=2):\n",
    "    print(\"generatoring data\")\n",
    "    out_data = []\n",
    "    for i in range(data.shape[0]):\n",
    "        noise = tf.random.normal([1, noise_dim])\n",
    "        if(decode_flag):\n",
    "            gen = decode(generator(noise, training=False)).numpy().tolist()[0]\n",
    "        else:\n",
    "            gen = generator(noise, training=False).numpy().tolist()[0]\n",
    "        out_data.append(gen)\n",
    "    #\n",
    "    print(\"formating data\")\n",
    "    out_file_name = \"out_dnum.txt\"\n",
    "    inp_file_name = \"input_dnum.txt\"\n",
    "    out_apriorifile_name = \"o_apriori.txt\"\n",
    "    inp_apriorifile_name = \"i_apriori.txt\"\n",
    "    inpdata=df.format_inpdata(data)\n",
    "    outdata=df.format_outdata(out_data, use_avg=useavg, avgbase=avgbase, limit=limit, bigest_num=bigest_num)\n",
    "    df.writedatafile(inpdata, outdata, inp_file_name, out_file_name)\n",
    "    print(\"aproring\")\n",
    "    df.apriori(cut, out_file_name, out_apriorifile_name)\n",
    "    df.apriori(cut, inp_file_name, inp_apriorifile_name)\n",
    "    #\n",
    "    print(\"showing data\")\n",
    "    print(\"n=1\")\n",
    "    inp_seq_y, inp_seq_x = df.read_n_seq(inp_apriorifile_name, 1)\n",
    "    out_seq_y, out_seq_x = df.read_n_seq(out_apriorifile_name, 1)\n",
    "    df.plt_format(inp_seq_x, inp_seq_y, out_seq_x, out_seq_y, True)\n",
    "    print(\"n=\", n)\n",
    "    inp_seq_y, inp_seq_x = df.read_n_seq(inp_apriorifile_name,n)\n",
    "    out_seq_y, out_seq_x = df.read_n_seq(out_apriorifile_name,n)\n",
    "    df.plt_format(inp_seq_x,inp_seq_y,out_seq_x,out_seq_y)\n",
    "show_result(out_data, data, False, avgbase=1)\n",
    "show_result(out_data, data, False, useavg=False, avgbase=1, limit=0.5, bigest_num=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
