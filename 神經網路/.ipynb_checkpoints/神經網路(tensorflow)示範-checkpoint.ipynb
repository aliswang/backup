{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype(\"float32\")/255\n",
    "y_train = tf.one_hot(y_train.reshape(y_train.shape[0],) ,depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#架構,訓練,執行方式\n",
    "#Model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "450/450 [==============================] - 1s 2ms/step - acc: 0.1191 - loss: 0.0925 - val_acc: 0.1488 - val_loss: 0.0907\n",
      "Epoch 2/3\n",
      "450/450 [==============================] - 1s 2ms/step - acc: 0.1676 - loss: 0.0897 - val_acc: 0.1860 - val_loss: 0.0886\n",
      "Epoch 3/3\n",
      "450/450 [==============================] - 1s 2ms/step - acc: 0.2009 - loss: 0.0878 - val_acc: 0.2142 - val_loss: 0.0871\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input((32, 32, 3)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=3, strides=1, padding='SAME', use_bias=False))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "def MeanSquaredError(y_true, y_pred):\n",
    "    return tf.reduce_mean((y_pred - y_true)**2, axis=-1)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\\\n",
    "              loss=MeanSquaredError,\\\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "his = model.fit(x=x_train, y=y_train, batch_size=100, epochs=3, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.11913333088159561, 0.16762222349643707, 0.2009333372116089],\n",
       " 'loss': [0.09252220392227173, 0.08966552466154099, 0.08781618624925613],\n",
       " 'val_acc': [0.14880000054836273, 0.1860000044107437, 0.2142000049352646],\n",
       " 'val_loss': [0.09067479521036148, 0.08858700096607208, 0.08710774779319763]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "his.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input((32,32,3)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=3,kernel_size=3,strides=1,padding='SAME',use_bias=False))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "noise_dim=1311\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 512\n",
    "dataset=tf.data.Dataset.from_tensor_slices((x_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "                loss=tf.losses.CategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 2.0058\n",
      "Epoch 2/3\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.8667\n",
      "Epoch 3/3\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.8139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f90549a5dd8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train,y=y_train,batch_size=100,epochs=3,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 1.0, 0.0, 5.032038349485916e-31, 0.0, 0.0, 0.0, 0.0]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "out = model.predict(x_test[:1]).tolist()[0]\n",
    "print(out)\n",
    "print(out.index(max(out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tf.keras.Input((32,32,3))\n",
    "x = tf.keras.layers.Conv2D(filters=3,kernel_size=3,strides=1,padding='SAME',use_bias=False)(inp)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(10)(x)\n",
    "out = tf.nn.softmax(x)\n",
    "model = tf.keras.Model(inputs=[inp],outputs=[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.9810\n",
      "Epoch 2/3\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.8338\n",
      "Epoch 3/3\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.7858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f90f14840b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "                loss=tf.losses.CategoricalCrossentropy())\n",
    "model.fit(x=x_train,y=y_train,batch_size=100,epochs=3,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 1.0, 0.0, 4.556552197516935e-17, 0.0, 0.0, 0.0, 0.0]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "out = model.predict(x_test[:1]).tolist()[0]\n",
    "print(out)\n",
    "print(out.index(max(out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class build_model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(build_model, self).__init__()\n",
    "        self.cov1 = tf.keras.layers.Conv2D(filters=3,kernel_size=3,strides=1,padding='SAME',use_bias=False)\n",
    "        self.Flatten = tf.keras.layers.Flatten()\n",
    "        self.den1 = tf.keras.layers.Dense(10)\n",
    "        \n",
    "    def call(self, x, training=True):\n",
    "        x = self.cov1(x)\n",
    "        x = self.Flatten(x)\n",
    "        x = self.den1(x)\n",
    "        x = tf.nn.softmax(x)\n",
    "        return x\n",
    "#可以細節調整模型 像是部分training=False\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 2.0418\n",
      "Epoch 2/3\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.8685\n",
      "Epoch 3/3\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.8077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f90f0c0abe0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "                loss=tf.losses.CategoricalCrossentropy())\n",
    "model.fit(x=x_train,y=y_train,batch_size=100,epochs=3,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model another way to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input((32, 32, 3)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=3, strides=1, padding='SAME', use_bias=False))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(0.01)\n",
    "loss_ = tf.losses.CategoricalCrossentropy()\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(60000).batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.7983518, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9112184, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7698287, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for img, label in dataset:\n",
    "        with tf.GradientTape() as tape :\n",
    "            out_label = model(img)\n",
    "            loss = loss_(label, out_label)\n",
    "        model_grd = tape.gradient(loss, model.trainable_variables)\n",
    "        opt.apply_gradients(zip(model_grd, model.trainable_variables))\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#show how to use\n",
    "out = model.predict(x_test[:1][:].astype(\"float64\")).tolist()[0]\n",
    "print(out)\n",
    "print(out.index(max(out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多重輸入輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inp_1 = tf.keras.Input((32,32,3))\n",
    "inp_2 = tf.keras.Input((32,32,3))\n",
    "x = tf.keras.layers.Conv2D(filters=3, kernel_size=3, strides=1, padding='SAME', use_bias=False)(inp_1)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(10)(x)\n",
    "out_1 = tf.nn.softmax(x)\n",
    "out_2 = x\n",
    "model = tf.keras.Model(inputs=[inp_1,inp_2],outputs=[out_1,out_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "500/500 [==============================] - 3s 5ms/step - tf_op_layer_Softmax_1_loss: 2.0092 - dense_4_loss: 0.0000e+00 - loss: 2.0092\n",
      "Epoch 2/3\n",
      "500/500 [==============================] - 2s 5ms/step - tf_op_layer_Softmax_1_loss: 1.8307 - dense_4_loss: 0.0000e+00 - loss: 1.8307\n",
      "Epoch 3/3\n",
      "500/500 [==============================] - 2s 5ms/step - tf_op_layer_Softmax_1_loss: 1.7819 - dense_4_loss: 0.0000e+00 - loss: 1.7819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f90f0befcf8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "inp_2 = np.zeros_like(x_train)\n",
    "out_2 = np.zeros_like(y_train)\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "                loss=tf.losses.CategoricalCrossentropy())\n",
    "model.fit(x=[x_train,inp_2], y=[y_train,out_2], batch_size=100, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#停止訓練與多重輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class build_model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(build_model, self).__init__()\n",
    "        self.cov1 = tf.keras.layers.Conv2D(filters=3,kernel_size=3,strides=1,padding='SAME',use_bias=False)\n",
    "        #加入trainable=False 停止訓練該層\n",
    "        #self.cov1 = tf.keras.layers.Conv2D(filters=3,kernel_size=3,strides=1,padding='SAME',use_bias=False,trainable=False)\n",
    "        self.Flatten = tf.keras.layers.Flatten()\n",
    "        self.den1 = tf.keras.layers.Dense(10)\n",
    "        \n",
    "    def call(self, x, training=True):\n",
    "        x = self.cov1(x)\n",
    "        x = self.Flatten(x)\n",
    "        x = self.den1(x)\n",
    "        out = tf.nn.softmax(x)\n",
    "        return out , x\n",
    "model = build_model()\n",
    "opt = tf.keras.optimizers.SGD(0.01)\n",
    "_loss = tf.losses.CategoricalCrossentropy()\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(60000).batch(500)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print(epoch, \"/\", epochs)\n",
    "    for img,label in dataset:\n",
    "        with tf.GradientTape() as tape :\n",
    "            out_label, x= model(img)\n",
    "            loss = _loss(label, out_label)\n",
    "        model_v = model.trainable_variables[:]\n",
    "        #暫時移除所需訓練的值\n",
    "        if(epoch == 2): \n",
    "            model_v.pop(0)\n",
    "        model_grd = tape.gradient(loss, model_v)\n",
    "        opt.apply_gradients(zip(model_grd, model_v))\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d_6/kernel:0' shape=(3, 3, 3, 3) dtype=float64, numpy=\n",
       " array([[[[-0.07305311, -0.05129496, -0.05837891],\n",
       "          [-0.32948079,  0.28690185, -0.28878378],\n",
       "          [ 0.10763157, -0.27217971,  0.23155475]],\n",
       " \n",
       "         [[-0.28139915,  0.23308579, -0.00507358],\n",
       "          [-0.30126506, -0.21878425, -0.14121097],\n",
       "          [-0.25369351,  0.25336639,  0.15263393]],\n",
       " \n",
       "         [[ 0.33075523, -0.05107876,  0.29964303],\n",
       "          [ 0.25812692,  0.28374645, -0.1587405 ],\n",
       "          [ 0.16731555, -0.16763706,  0.15459016]]],\n",
       " \n",
       " \n",
       "        [[[ 0.17477692,  0.16637755,  0.2059963 ],\n",
       "          [-0.15789399, -0.17786933, -0.06391948],\n",
       "          [ 0.27307967, -0.29275755,  0.06018953]],\n",
       " \n",
       "         [[-0.12113646, -0.19399768,  0.26888955],\n",
       "          [ 0.20235816,  0.18294717,  0.26237495],\n",
       "          [-0.31775366,  0.32435102,  0.27087763]],\n",
       " \n",
       "         [[ 0.10089782,  0.15876503,  0.1595574 ],\n",
       "          [ 0.05436451,  0.20800198,  0.14742802],\n",
       "          [-0.10613277, -0.02179938, -0.04764796]]],\n",
       " \n",
       " \n",
       "        [[[-0.17817218,  0.05705751,  0.11045993],\n",
       "          [-0.22713119, -0.12041885, -0.01583531],\n",
       "          [ 0.00478892, -0.08083145,  0.1859843 ]],\n",
       " \n",
       "         [[-0.1791271 ,  0.15517947, -0.06876831],\n",
       "          [ 0.13441518,  0.05281251,  0.14425197],\n",
       "          [ 0.13035994,  0.30495546,  0.13078562]],\n",
       " \n",
       "         [[-0.04719995,  0.08374897,  0.30337606],\n",
       "          [ 0.05513751, -0.20134706,  0.16733537],\n",
       "          [-0.27380009, -0.20885302, -0.32747538]]]])>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#讀取層數參數\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input((32, 32, 3)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=3, strides=1, padding='SAME', use_bias=False))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練方法定義\n",
    "def train(dense_dim):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    x_train = x_train.astype(\"float32\")/255\n",
    "    y_train = tf.one_hot(y_train.reshape(y_train.shape[0],) , depth=10)\n",
    "    def build_model(dense_dim):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.Input((32,32,3)))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(dense_dim))\n",
    "        model.add(tf.keras.layers.Dense(10,activation=\"softmax\"))\n",
    "        return model\n",
    "    model = build_model(dense_dim)\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\\\n",
    "                  loss=tf.losses.CategoricalCrossentropy(),\\\n",
    "                  metrics=[\"acc\"])\n",
    "\n",
    "    his = model.fit(x=x_train, y=y_train, batch_size=1000, epochs=3, validation_split=0.1, verbose=1)\n",
    "    #model.save_weights(\"test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "45/45 [==============================] - ETA: 0s - acc: 0.1270 - loss: 2.591 - ETA: 0s - acc: 0.1248 - loss: 2.444 - ETA: 0s - acc: 0.1270 - loss: 2.397 - ETA: 0s - acc: 0.1440 - loss: 2.349 - ETA: 0s - acc: 0.1522 - loss: 2.326 - ETA: 0s - acc: 0.1600 - loss: 2.299 - ETA: 0s - acc: 0.1687 - loss: 2.278 - ETA: 0s - acc: 0.1724 - loss: 2.266 - ETA: 0s - acc: 0.1771 - loss: 2.253 - ETA: 0s - acc: 0.1821 - loss: 2.240 - ETA: 0s - acc: 0.1885 - loss: 2.227 - ETA: 0s - acc: 0.1925 - loss: 2.215 - 1s 18ms/step - acc: 0.1925 - loss: 2.2153 - val_loss: 2.0819 - val_acc: 0.2626\n",
      "Epoch 2/3\n",
      "45/45 [==============================] - ETA: 0s - acc: 0.2660 - loss: 2.056 - ETA: 0s - acc: 0.2520 - loss: 2.082 - ETA: 0s - acc: 0.2501 - loss: 2.079 - ETA: 0s - acc: 0.2546 - loss: 2.073 - ETA: 0s - acc: 0.2542 - loss: 2.069 - ETA: 0s - acc: 0.2578 - loss: 2.062 - ETA: 0s - acc: 0.2604 - loss: 2.057 - ETA: 0s - acc: 0.2593 - loss: 2.057 - ETA: 0s - acc: 0.2598 - loss: 2.055 - ETA: 0s - acc: 0.2624 - loss: 2.050 - ETA: 0s - acc: 0.2648 - loss: 2.046 - ETA: 0s - acc: 0.2653 - loss: 2.043 - 1s 16ms/step - acc: 0.2653 - loss: 2.0439 - val_loss: 2.0202 - val_acc: 0.2814\n",
      "Epoch 3/3\n",
      "45/45 [==============================] - ETA: 0s - acc: 0.2980 - loss: 2.007 - ETA: 0s - acc: 0.2942 - loss: 1.990 - ETA: 0s - acc: 0.2962 - loss: 1.990 - ETA: 0s - acc: 0.2941 - loss: 1.991 - ETA: 0s - acc: 0.2931 - loss: 1.992 - ETA: 0s - acc: 0.2932 - loss: 1.993 - ETA: 0s - acc: 0.2950 - loss: 1.988 - ETA: 0s - acc: 0.2967 - loss: 1.984 - ETA: 0s - acc: 0.2980 - loss: 1.982 - ETA: 0s - acc: 0.2982 - loss: 1.981 - ETA: 0s - acc: 0.2989 - loss: 1.980 - ETA: 0s - acc: 0.2987 - loss: 1.980 - 1s 16ms/step - acc: 0.2987 - loss: 1.9803 - val_loss: 1.9691 - val_acc: 0.3012\n"
     ]
    }
   ],
   "source": [
    "#通過mp強制停止並清除緩存空見\n",
    "import multiprocessing\n",
    "dense_dim = 100\n",
    "mp = multiprocessing.Process(target=train,args=(dense_dim,))\n",
    "mp.start()\n",
    "mp.join()\n",
    "mp.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
